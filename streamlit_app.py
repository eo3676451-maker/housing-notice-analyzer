"""
í•œí™” í¬ë ˆë‚˜ ë¶€ì‚°ëŒ€ì—° PDF ë¶„ì„ ì›¹ì•± (Streamlit)
"""
import streamlit as st
import pdfplumber
import pandas as pd
import re
import tempfile
from io import BytesIO

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì…ì£¼ìëª¨ì§‘ê³µê³  ë¶„ì„ê¸°",
    page_icon="ğŸ ",
    layout="wide"
)

# ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        margin-bottom: 1rem;
    }
    .info-box {
        background-color: #E3F2FD;
        padding: 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
    }
    .stDataFrame {
        width: 100%;
    }
</style>
""", unsafe_allow_html=True)

# ============================
#  ë¶„ì„ í•¨ìˆ˜ë“¤
# ============================

def parse_complex_name(text: str):
    """ë‹¨ì§€ëª… ì¶”ì¶œ"""
    for line in text.splitlines():
        line = line.strip()
        if "ì…ì£¼ìëª¨ì§‘ê³µê³ " in line:
            raw = line.replace("ì…ì£¼ìëª¨ì§‘ê³µê³ ", "").strip()
            name = re.sub(r"\s+", " ", raw).strip(" ,Â·-")
            return name or None
    return None


def parse_location(text: str):
    """ê³µê¸‰ìœ„ì¹˜ ì¶”ì¶œ"""
    keywords = ["ê³µê¸‰ìœ„ì¹˜", "ì‚¬ì—…ìœ„ì¹˜", "ê±´ì„¤ìœ„ì¹˜", "ëŒ€ì§€ìœ„ì¹˜"]
    for line in text.splitlines():
        for key in keywords:
            if key in line:
                cleaned = line.replace(key, "").replace(":", "").replace("â– ", "").replace("ìœ„ì¹˜", "").strip()
                return re.sub(r"\s+", " ", cleaned)
    return None


def extract_move_in_date(text: str):
    """ì…ì£¼ì˜ˆì •ì¼ ì¶”ì¶œ"""
    for line in text.splitlines():
        s = line.strip().replace(" ", "")
        if any(k in s for k in ["ì…ì£¼ì‹œê¸°", "ì…ì£¼ì˜ˆì •", "ì…ì£¼ì˜ˆì •ì¼"]):
            m = re.search(r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”", line)
            if m:
                return f"{m.group(1)}ë…„ {m.group(2)}ì›”"
    return None


def extract_companies(text: str):
    """ì‹œí–‰ì‚¬/ì‹œê³µì‚¬/ë¶„ì–‘ëŒ€í–‰ì‚¬ ì¶”ì¶œ (ê°•í™” ë²„ì „)"""
    companies = {"ì‹œí–‰ì‚¬": None, "ì‹œê³µì‚¬": None, "ë¶„ì–‘ëŒ€í–‰ì‚¬": None}
    
    # íšŒì‚¬ëª… í‚¤ì›Œë“œ
    company_keywords = ["ì¡°í•©", "ê±´ì„¤", "ãˆœ", "(ì£¼)", "ê°œë°œ", "ê³µì‚¬", "ê¸°ì—…", "ì£¼ì‹íšŒì‚¬", "ë””ì•¤ì”¨", "ë””ì—”ì”¨"]
    
    # í…ìŠ¤íŠ¸ ì •ê·œí™”
    norm_text = text.replace("ï¼š", ":").replace("\n", " ")
    
    # 1ì°¨: íŒ¨í„´ ë§¤ì¹­
    patterns = {
        "ì‹œí–‰ì‚¬": [
            r"ì‚¬ì—…ì£¼ì²´\s*[:\s]\s*([^\n,]+)",
            r"ì‹œí–‰ì\s*[:\s]\s*([^\n,]+)",
            r"ì‹œí–‰ì‚¬\s*[:\s]\s*([^\n,]+)",
            r"ì‚¬ì—…ì‹œí–‰ì\s*[:\s]\s*([^\n,]+)",
        ],
        "ì‹œê³µì‚¬": [
            r"ì‹œê³µì‚¬\s*[:\s]\s*([^\n,]+)",
            r"ì‹œê³µì\s*[:\s]\s*([^\n,]+)",
            r"ì‹œê³µ\s*[:\s]\s*([^\n,]+(?:ê±´ì„¤|ê³µì‚¬|ê¸°ì—…)[^\n,]*)",
        ],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [
            r"ë¶„ì–‘ëŒ€í–‰ì‚¬\s*[:\s]\s*([^\n,]+)",
            r"ë¶„ì–‘ëŒ€í–‰\s*[:\s]\s*([^\n,]+)",
        ]
    }
    
    for role, pats in patterns.items():
        for pattern in pats:
            match = re.search(pattern, norm_text)
            if match:
                name = match.group(1).strip()
                # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
                name = re.sub(r'\s+', ' ', name)
                name = name.split('â€»')[0].strip()
                name = name.split('(ë‹¨')[0].strip()
                name = name.split('ë²•ì¸')[0].strip() if 'ë²•ì¸' in name and len(name) > 20 else name
                
                if any(k in name for k in company_keywords) and len(name) <= 50:
                    companies[role] = name
                    break
    
    return companies


def extract_companies_from_table(pdf):
    """PDF í…Œì´ë¸”ì—ì„œ íšŒì‚¬ ì •ë³´ ì¶”ì¶œ"""
    companies = {"ì‹œí–‰ì‚¬": None, "ì‹œê³µì‚¬": None, "ë¶„ì–‘ëŒ€í–‰ì‚¬": None}
    
    company_keywords = ["ì¡°í•©", "ê±´ì„¤", "ãˆœ", "(ì£¼)", "ê°œë°œ", "ê³µì‚¬", "ê¸°ì—…", "ì£¼ì‹íšŒì‚¬", "ë””ì•¤ì”¨"]
    
    # ë§ˆì§€ë§‰ 15í˜ì´ì§€ì—ì„œ ê²€ìƒ‰ (íšŒì‚¬ì •ë³´ëŠ” ë³´í†µ ë’¤ìª½ì— ìˆìŒ)
    start_page = max(0, len(pdf.pages) - 15)
    
    for page_idx in range(start_page, len(pdf.pages)):
        page = pdf.pages[page_idx]
        text = page.extract_text() or ""
        
        # ì‚¬ì—…ì£¼ì²´/ì‹œê³µì‚¬ í‚¤ì›Œë“œê°€ ìˆëŠ” í˜ì´ì§€ì—ì„œë§Œ ë¶„ì„
        if not ("ì‚¬ì—…ì£¼ì²´" in text or "ì‹œê³µì‚¬" in text or "ì‹œê³µ" in text):
            continue
        
        tables = page.extract_tables() or []
        
        for table in tables:
            if not table or len(table) < 2:
                continue
            
            all_text = ' '.join(' '.join(str(c) for c in row if c) for row in table)
            
            # íšŒì‚¬ì •ë³´ í…Œì´ë¸”ì¸ì§€ í™•ì¸
            if not ("ì‚¬ì—…ì£¼ì²´" in all_text or "ì‹œí–‰" in all_text) or "ì‹œê³µ" not in all_text:
                continue
            
            # í—¤ë” ì°¾ê¸°
            for r_idx, row in enumerate(table[:3]):
                row_text = ' '.join(str(c).replace(' ', '') for c in row if c)
                
                if "ì‚¬ì—…ì£¼ì²´" in row_text or "ì‹œí–‰" in row_text:
                    # ì´ í–‰ì„ í—¤ë”ë¡œ, ë‹¤ìŒ í–‰ì—ì„œ ë°ì´í„° ì¶”ì¶œ
                    header_cols = {}
                    for c_idx, cell in enumerate(row):
                        cell_clean = str(cell).replace(' ', '').replace('\n', '') if cell else ''
                        if 'ì‚¬ì—…ì£¼ì²´' in cell_clean or 'ì‹œí–‰' in cell_clean:
                            header_cols['ì‹œí–‰ì‚¬'] = c_idx
                        elif 'ì‹œê³µì‚¬' in cell_clean or ('ì‹œê³µ' in cell_clean and 'ë¶„ì–‘' not in cell_clean):
                            header_cols['ì‹œê³µì‚¬'] = c_idx
                        elif 'ë¶„ì–‘ëŒ€í–‰' in cell_clean:
                            header_cols['ë¶„ì–‘ëŒ€í–‰ì‚¬'] = c_idx
                    
                    # ë°ì´í„° í–‰ ì²˜ë¦¬
                    for data_row in table[r_idx + 1:]:
                        if not data_row:
                            continue
                        
                        for role, col_idx in header_cols.items():
                            if col_idx < len(data_row) and data_row[col_idx]:
                                name = str(data_row[col_idx]).replace('\n', ' ').strip()
                                if any(k in name for k in company_keywords) and companies[role] is None:
                                    companies[role] = name[:50]
                    
                    if all(companies.values()):
                        return companies
    
    return companies


def extract_scale(text: str):
    """ê³µê¸‰ê·œëª¨ ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    
    # "ê³µê¸‰ê·œëª¨" í‚¤ì›Œë“œê°€ ìˆëŠ” ë¼ì¸ ì „ì²´ ì¶”ì¶œ
    for line in text.splitlines():
        line = line.strip()
        if "ê³µê¸‰ê·œëª¨" in line:
            # â–  ê³µê¸‰ê·œëª¨ : ë‹¤ìŒ ë‚´ìš© ì¶”ì¶œ
            cleaned = line.replace("â– ", "").replace("â—", "").strip()
            cleaned = cleaned.replace("ê³µê¸‰ê·œëª¨", "").replace(":", "").strip()
            if cleaned and len(cleaned) > 10:
                return cleaned
    
    # ëŒ€ì²´ íŒ¨í„´: ì§€í•˜/ì§€ìƒ/ë™ ì •ë³´ ì¡°í•©
    scale_parts = []
    
    floor_match = re.search(r'ì§€í•˜\s*(\d+)\s*ì¸µ[^\d]*ì§€ìƒ[^\d]*ìµœê³ ?\s*(\d+)\s*ì¸µ', text)
    if floor_match:
        scale_parts.append(f"ì§€í•˜ {floor_match.group(1)}ì¸µ, ì§€ìƒ ìµœê³  {floor_match.group(2)}ì¸µ")
    
    dong_match = re.search(r'(\d+)\s*ê°œ?\s*ë™', text)
    if dong_match:
        scale_parts.append(f"{dong_match.group(1)}ê°œë™")
    
    total_match = re.search(r'ì´\s*(\d+)\s*ì„¸ëŒ€', text.replace(',', ''))
    if total_match:
        scale_parts.append(f"ì´ {total_match.group(1)}ì„¸ëŒ€")
    
    return ', '.join(scale_parts) if scale_parts else None


def extract_schedule_from_table(pdf):
    """PDF í…Œì´ë¸”ì—ì„œ ì²­ì•½ ì¼ì • ì¶”ì¶œ (ê°•í™” ë²„ì „)"""
    schedule = {}
    
    # ì¼ì • í‚¤ì›Œë“œ ë§¤í•‘
    keyword_map = {
        "ì…ì£¼ìëª¨ì§‘ê³µê³ ": "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "ëª¨ì§‘ê³µê³ ì¼": "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "íŠ¹ë³„ê³µê¸‰": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "íŠ¹ë³„ê³µê¸‰ì ‘ìˆ˜": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "1ìˆœìœ„": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰1ìˆœìœ„": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "2ìˆœìœ„": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰2ìˆœìœ„": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ë‹¹ì²¨ìë°œí‘œ": "ë‹¹ì²¨ì ë°œí‘œì¼",
        "ë‹¹ì²¨ì ë°œí‘œ": "ë‹¹ì²¨ì ë°œí‘œì¼",
        "ì„œë¥˜ì ‘ìˆ˜": "ì„œë¥˜ì ‘ìˆ˜",
        "ê³„ì•½ì²´ê²°": "ê³„ì•½ì²´ê²°",
        "ì •ë‹¹ê³„ì•½": "ê³„ì•½ì²´ê²°",
    }
    
    date_pattern = r'(\d{4}[.]\d{1,2}[.]\d{1,2})'
    
    for page_idx, page in enumerate(pdf.pages[:15]):  # ì• 15í˜ì´ì§€ë§Œ
        text = page.extract_text() or ""
        
        # ì¼ì • ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ” í˜ì´ì§€ì—ì„œë§Œ ë¶„ì„
        if not ("ê³µê³ " in text or "ì ‘ìˆ˜" in text or "ë‹¹ì²¨" in text or "ì²­ì•½ì¼ì •" in text):
            continue
        
        tables = page.extract_tables() or []
        
        for table in tables:
            if not table or len(table) < 2:
                continue
            
            # í–‰ ë‹¨ìœ„ë¡œ ë¶„ì„ (ê°€ë¡œ í˜•íƒœ í…Œì´ë¸”)
            for row in table:
                if not row:
                    continue
                
                for c_idx, cell in enumerate(row):
                    if not cell:
                        continue
                    
                    cell_clean = str(cell).replace(' ', '').replace('\n', '')
                    
                    for keyword, label in keyword_map.items():
                        if keyword.replace(' ', '') in cell_clean:
                            # ê°™ì€ í–‰ì—ì„œ ë‚ ì§œ ì°¾ê¸°
                            for other_cell in row[c_idx+1:]:
                                if other_cell:
                                    date_match = re.search(date_pattern, str(other_cell))
                                    if date_match:
                                        # ë…„ë„ê°€ 2024~2027 ë²”ìœ„ì¸ì§€ í™•ì¸
                                        date_str = date_match.group(1)
                                        year = int(date_str.split('.')[0])
                                        if 2024 <= year <= 2027:
                                            if label not in schedule:
                                                schedule[label] = date_str
                                        break
                            
                            # ë‹¤ìŒ í–‰ì—ì„œ ë‚ ì§œ ì°¾ê¸° (ì„¸ë¡œ í˜•íƒœ)
                            row_idx = table.index(row)
                            if row_idx + 1 < len(table):
                                next_row = table[row_idx + 1]
                                if c_idx < len(next_row) and next_row[c_idx]:
                                    date_match = re.search(date_pattern, str(next_row[c_idx]))
                                    if date_match:
                                        date_str = date_match.group(1)
                                        year = int(date_str.split('.')[0])
                                        if 2024 <= year <= 2027:
                                            if label not in schedule:
                                                schedule[label] = date_str
    
    # ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ìˆœì„œ ìœ ì§€)
    result = []
    order = ["ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼", "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼", "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼", 
             "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼", "ë‹¹ì²¨ì ë°œí‘œì¼", "ì„œë¥˜ì ‘ìˆ˜", "ê³„ì•½ì²´ê²°"]
    
    for label in order:
        if label in schedule:
            result.append({"ì¼ì •": label, "ë‚ ì§œ": schedule[label]})
    
    return result


def extract_price_table(pdf, pages_to_check=None):
    """ê³µê¸‰ê¸ˆì•¡í‘œ ì¶”ì¶œ (ê°•í™”ëœ ë²„ì „)"""
    price_data = []
    
    # ê³µê¸‰ê¸ˆì•¡ ê´€ë ¨ í˜ì´ì§€ ë¨¼ì € ì°¾ê¸°
    price_pages = set()
    for i, page in enumerate(pdf.pages):
        text = page.extract_text() or ""
        if ("ê³µê¸‰ê¸ˆì•¡" in text or "ë¶„ì–‘ê¸ˆì•¡" in text) and ("ì£¼íƒí˜•" in text or "íƒ€ì…" in text or "ë™" in text):
            price_pages.add(i)
            # ë‹¤ìŒ í˜ì´ì§€ë„ ì¶”ê°€ (ì—°ì† í˜ì´ì§€ ì§€ì›)
            if i + 1 < len(pdf.pages):
                price_pages.add(i + 1)
            # ì´ì „ í˜ì´ì§€ë„ ì¶”ê°€ (í˜¹ì‹œ í—¤ë”ê°€ ì´ì „ í˜ì´ì§€ì— ìˆëŠ” ê²½ìš°)
            if i > 0:
                price_pages.add(i - 1)
    
    if not price_pages:
        # í‚¤ì›Œë“œë¡œ ëª» ì°¾ìœ¼ë©´ ì• 20í˜ì´ì§€ ê²€ìƒ‰
        price_pages = set(range(min(20, len(pdf.pages))))
    
    # ì •ë ¬í•´ì„œ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
    for page_idx in sorted(price_pages):
        page = pdf.pages[page_idx]
        tables = page.extract_tables()
        
        for table in tables:
            if len(table) < 3:
                continue
            
            # í…Œì´ë¸” ì „ì²´ í…ìŠ¤íŠ¸ í™•ì¸
            all_text = ' '.join(' '.join(str(c) for c in row if c) for row in table)
            
            # ê¸ˆì•¡í‘œì¸ì§€ í™•ì¸ (ë¶„ì–‘ê¸ˆì•¡, ëŒ€ì§€ë¹„, ê±´ì¶•ë¹„ í‚¤ì›Œë“œ ë˜ëŠ” í° ìˆ«ìê°€ ìˆëŠ” ê²½ìš°)
            has_price_keyword = ("ë¶„ì–‘ê¸ˆì•¡" in all_text or "ëŒ€ì§€ë¹„" in all_text or "ê³µê¸‰ê¸ˆì•¡" in all_text)
            
            # 1ì–µ ì´ìƒ ìˆ«ìê°€ ì—¬ëŸ¬ ê°œ ìˆìœ¼ë©´ ê¸ˆì•¡í‘œë¡œ ê°„ì£¼
            big_numbers = re.findall(r'\d{9,}', all_text.replace(',', ''))
            has_big_numbers = len(big_numbers) >= 2
            
            if not has_price_keyword and not has_big_numbers:
                continue
            
            # í—¤ë” í–‰ ì°¾ê¸° (ë¶„ì–‘ê¸ˆì•¡, ëŒ€ì§€ë¹„, ê±´ì¶•ë¹„ ë“±ì´ ìˆëŠ” í–‰)
            header_row_idx = None
            for r_idx, row in enumerate(table[:5]):  # ì²˜ìŒ 5í–‰ì—ì„œ í—¤ë” ì°¾ê¸°
                row_text = ' '.join(str(c) for c in row if c)
                if "ëŒ€ì§€ë¹„" in row_text or "ê±´ì¶•ë¹„" in row_text or "ë¶„ì–‘ê¸ˆì•¡" in row_text:
                    header_row_idx = r_idx
                    break
            
            # í—¤ë” ì—†ìœ¼ë©´ ì²« í–‰ë¶€í„° ì²˜ë¦¬ (ì—°ì† í˜ì´ì§€ ì§€ì›)
            start_row = header_row_idx + 1 if header_row_idx is not None else 0
            
            # ë°ì´í„° í–‰ ì²˜ë¦¬
            for row in table[start_row:]:
                if len(row) < 8:
                    continue
                
                try:
                    # ê³ ì • ì¸ë±ìŠ¤ ê¸°ë°˜ ì¶”ì¶œ (í…Œì´ë¸” êµ¬ì¡° ë¶„ì„ ê²°ê³¼)
                    # [0] ì•½ì‹í‘œê¸°, [1] ê³µê¸‰ë©´ì , [2] ë™ë³„ë¼ì¸, [3] ì¸µ, [4] ì„¸ëŒ€ìˆ˜
                    # [5] ëŒ€ì§€ë¹„, [6] ê±´ì¶•ë¹„, [7] ë¶„ì–‘ê¸ˆì•¡ í•©ê³„
                    
                    # ë¶„ì–‘ê¸ˆì•¡ í•©ê³„ í™•ì¸ (ì¸ë±ìŠ¤ 7)
                    total_str = str(row[7]).replace(',', '').replace(' ', '').strip() if row[7] else ''
                    
                    # ë¶„ì–‘ê¸ˆì•¡ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                    if not total_str.isdigit() or int(total_str) < 100000000:
                        continue
                    
                    total_price = int(total_str)
                    
                    # ê° í•„ë“œ ì¶”ì¶œ
                    housing_type = str(row[0]).strip() if row[0] else ""
                    dong_line = str(row[2]).replace('\n', ' ').strip() if row[2] else ""
                    floor = str(row[3]).strip() if row[3] else ""
                    units = str(row[4]).strip() if row[4] else ""
                    
                    # ëŒ€ì§€ë¹„, ê±´ì¶•ë¹„
                    land_str = str(row[5]).replace(',', '').strip() if row[5] else ''
                    build_str = str(row[6]).replace(',', '').strip() if row[6] else ''
                    
                    land_price = int(land_str) if land_str.isdigit() else 0
                    build_price = int(build_str) if build_str.isdigit() else 0
                    
                    price_data.append({
                        "ì£¼íƒí˜•": housing_type,
                        "ë™/ë¼ì¸": dong_line,
                        "ì¸µ": floor,
                        "ì„¸ëŒ€ìˆ˜": units,
                        "ëŒ€ì§€ë¹„": land_price,
                        "ê±´ì¶•ë¹„": build_price,
                        "ë¶„ì–‘ê°€ í•©ê³„": total_price
                    })
                    
                except Exception as e:
                    continue
    
    # ì¤‘ë³µ ì œê±° (ë™/ë¼ì¸ + ì¸µ + ì„¸ëŒ€ìˆ˜ + ë¶„ì–‘ê°€ í•©ê³„ ê¸°ì¤€)
    seen = set()
    unique_data = []
    for item in price_data:
        key = (
            item.get("ë™/ë¼ì¸", ""),
            item.get("ì¸µ", ""),
            item.get("ì„¸ëŒ€ìˆ˜", ""),
            item.get("ë¶„ì–‘ê°€ í•©ê³„", 0)
        )
        if key not in seen:
            seen.add(key)
            unique_data.append(item)
    
    return unique_data




def extract_supply_table(pdf):
    """ê³µê¸‰ëŒ€ìƒ (ì£¼íƒí˜•ë³„ ì„¸ëŒ€ìˆ˜) ì¶”ì¶œ"""
    supply_data = []
    
    for page_idx in range(min(15, len(pdf.pages))):
        page = pdf.pages[page_idx]
        text = page.extract_text() or ""
        
        if "ê³µê¸‰ëŒ€ìƒ" not in text and ("ì£¼íƒí˜•" not in text or "ì„¸ëŒ€" not in text):
            continue
        
        tables = page.extract_tables()
        
        for table in tables:
            if len(table) < 3:
                continue
                
            header = table[0] if table else []
            header_str = ' '.join(str(h) for h in header if h)
            
            if ("ì£¼íƒí˜•" in header_str or "íƒ€ì…" in header_str) and ("ì„¸ëŒ€" in header_str or "ê³µê¸‰" in header_str):
                for row in table[2:]:
                    if len(row) >= 10:
                        try:
                            housing_type = str(row[2]).strip() if row[2] else str(row[1]).strip() if row[1] else ""
                            if re.match(r'\d+\.\d+', housing_type):
                                supply_data.append({
                                    "ì£¼íƒí˜•": housing_type,
                                    "ì „ìš©ë©´ì ": str(row[4]).strip() if len(row) > 4 and row[4] else "",
                                    "ê³µê¸‰ë©´ì ": str(row[6]).strip() if len(row) > 6 and row[6] else "",
                                    "ì´ì„¸ëŒ€ìˆ˜": str(row[10]).strip() if len(row) > 10 and row[10] else "",
                                })
                        except:
                            pass
                break  # ì²« ë²ˆì§¸ ì í•©í•œ í…Œì´ë¸”ë§Œ
        
        if supply_data:
            break
    
    return supply_data


# ============================
#  ë©”ì¸ UI
# ============================

st.markdown('<div class="main-header">ğŸ  ì…ì£¼ìëª¨ì§‘ê³µê³  PDF ë¶„ì„ê¸°</div>', unsafe_allow_html=True)
st.markdown("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì£¼ìš” ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“„ ëª¨ì§‘ê³µê³  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['pdf'])

if uploaded_file:
    with st.spinner("PDF ë¶„ì„ ì¤‘..."):
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name
        
        try:
            with pdfplumber.open(tmp_path) as pdf:
                # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                full_text = ""
                for page in pdf.pages:
                    full_text += (page.extract_text() or "") + "\n"
                
                # ì •ë³´ ì¶”ì¶œ
                complex_name = parse_complex_name(full_text)
                location = parse_location(full_text)
                move_in = extract_move_in_date(full_text)
                scale = extract_scale(full_text)  # ê·œëª¨ ì •ë³´ ì¶”ê°€
                
                # íšŒì‚¬ ì •ë³´ - í…ìŠ¤íŠ¸ + í…Œì´ë¸”ì—ì„œ ì¶”ì¶œ
                companies = extract_companies(full_text)
                table_companies = extract_companies_from_table(pdf)
                # í…Œì´ë¸”ì—ì„œ ì¶”ì¶œí•œ ì •ë³´ë¡œ ë³´ì™„
                for role in ["ì‹œí–‰ì‚¬", "ì‹œê³µì‚¬", "ë¶„ì–‘ëŒ€í–‰ì‚¬"]:
                    if not companies.get(role) and table_companies.get(role):
                        companies[role] = table_companies[role]
                
                # ì²­ì•½ ì¼ì • - í…Œì´ë¸”ì—ì„œ ì¶”ì¶œ
                schedule = extract_schedule_from_table(pdf)
                
                price_data = extract_price_table(pdf)
                supply_data = extract_supply_table(pdf)
                
                # ì„¸ëŒ€ìˆ˜ ì¶”ì¶œ
                total_match = re.search(r'ì´\s*(\d+)\s*ì„¸ëŒ€', full_text.replace(',', ''))
                total_units = total_match.group(1) if total_match else "N/A"
                
                # ê²°ê³¼ í‘œì‹œ
                st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                
                # ê¸°ë³¸ ì •ë³´
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ“Œ ê¸°ë³¸ ì •ë³´")
                    st.markdown(f"""
                    | í•­ëª© | ë‚´ìš© |
                    |------|------|
                    | **ë‹¨ì§€ëª…** | {complex_name or 'N/A'} |
                    | **ê³µê¸‰ìœ„ì¹˜** | {location or 'N/A'} |
                    | **ì´ ì„¸ëŒ€ìˆ˜** | {total_units}ì„¸ëŒ€ |
                    | **ê·œëª¨** | {scale or 'N/A'} |
                    | **ì…ì£¼ì˜ˆì •ì¼** | {move_in or 'N/A'} |
                    """)
                
                with col2:
                    st.subheader("ğŸ¢ ì‚¬ì—… ì£¼ì²´")
                    st.markdown(f"""
                    | êµ¬ë¶„ | íšŒì‚¬ëª… |
                    |------|--------|
                    | **ì‹œí–‰ì‚¬** | {companies.get('ì‹œí–‰ì‚¬') or 'N/A'} |
                    | **ì‹œê³µì‚¬** | {companies.get('ì‹œê³µì‚¬') or 'N/A'} |
                    | **ë¶„ì–‘ëŒ€í–‰ì‚¬** | {companies.get('ë¶„ì–‘ëŒ€í–‰ì‚¬') or 'N/A'} |
                    """)
                
                # ì²­ì•½ ì¼ì •
                if schedule:
                    st.subheader("ğŸ“… ì²­ì•½ ì¼ì •")
                    df_schedule = pd.DataFrame(schedule)
                    st.dataframe(df_schedule, use_container_width=True, hide_index=True)
                
                # ê³µê¸‰ëŒ€ìƒí‘œ
                if supply_data:
                    st.subheader("ğŸ  ì£¼íƒí˜•ë³„ ì„¸ëŒ€ìˆ˜")
                    df_supply = pd.DataFrame(supply_data)
                    st.dataframe(df_supply, use_container_width=True, hide_index=True)
                
                # ê³µê¸‰ê¸ˆì•¡í‘œ
                if price_data:
                    st.subheader("ğŸ’° ê³µê¸‰ê¸ˆì•¡í‘œ")
                    df_price = pd.DataFrame(price_data)
                    
                    # ê¸ˆì•¡ í¬ë§·íŒ…
                    df_price['ë¶„ì–‘ê°€ í•©ê³„'] = df_price['ë¶„ì–‘ê°€ í•©ê³„'].apply(lambda x: f"{x:,}ì›")
                    df_price['ëŒ€ì§€ë¹„'] = df_price['ëŒ€ì§€ë¹„'].apply(lambda x: f"{x:,}ì›" if x > 0 else "")
                    df_price['ê±´ì¶•ë¹„'] = df_price['ê±´ì¶•ë¹„'].apply(lambda x: f"{x:,}ì›" if x > 0 else "")
                    
                    st.dataframe(df_price, use_container_width=True, hide_index=True)
                else:
                    st.info("ê³µê¸‰ê¸ˆì•¡í‘œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. PDF êµ¬ì¡°ì— ë”°ë¼ ì¶”ì¶œì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.subheader("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                
                # ì—‘ì…€ íŒŒì¼ ìƒì„±
                output = BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    # ê¸°ë³¸ì •ë³´
                    basic_info = pd.DataFrame([
                        ["ë‹¨ì§€ëª…", complex_name or ""],
                        ["ê³µê¸‰ìœ„ì¹˜", location or ""],
                        ["ì´ ì„¸ëŒ€ìˆ˜", f"{total_units}ì„¸ëŒ€"],
                        ["ê·œëª¨", scale or ""],
                        ["ì…ì£¼ì˜ˆì •ì¼", move_in or ""],
                        ["ì‹œí–‰ì‚¬", companies.get('ì‹œí–‰ì‚¬') or ""],
                        ["ì‹œê³µì‚¬", companies.get('ì‹œê³µì‚¬') or ""],
                        ["ë¶„ì–‘ëŒ€í–‰ì‚¬", companies.get('ë¶„ì–‘ëŒ€í–‰ì‚¬') or ""],
                    ], columns=["í•­ëª©", "ë‚´ìš©"])
                    basic_info.to_excel(writer, sheet_name='ê¸°ë³¸ì •ë³´', index=False)
                    
                    # ì²­ì•½ì¼ì •
                    if schedule:
                        pd.DataFrame(schedule).to_excel(writer, sheet_name='ì²­ì•½ì¼ì •', index=False)
                    
                    # ê³µê¸‰ëŒ€ìƒ
                    if supply_data:
                        pd.DataFrame(supply_data).to_excel(writer, sheet_name='ì£¼íƒí˜•ë³„ ì„¸ëŒ€ìˆ˜', index=False)
                    
                    # ê³µê¸‰ê¸ˆì•¡í‘œ
                    if price_data:
                        pd.DataFrame(price_data).to_excel(writer, sheet_name='ê³µê¸‰ê¸ˆì•¡í‘œ', index=False)
                
                output.seek(0)
                
                file_name = f"{complex_name or 'analysis'}_ë¶„ì„ê²°ê³¼.xlsx"
                st.download_button(
                    label="ğŸ“Š ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=output,
                    file_name=file_name,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
        except Exception as e:
            st.error(f"âŒ PDF ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            import os
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)

else:
    st.info("ğŸ‘† PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
    
    # ì‚¬ìš© ê°€ì´ë“œ
    with st.expander("ğŸ“– ì‚¬ìš© ë°©ë²•"):
        st.markdown("""
        1. **PDF ì—…ë¡œë“œ**: ì…ì£¼ìëª¨ì§‘ê³µê³  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤
        2. **ìë™ ë¶„ì„**: ë‹¨ì§€ì •ë³´, ì‚¬ì—…ì£¼ì²´, ì²­ì•½ì¼ì •, ê³µê¸‰ê¸ˆì•¡í‘œë¥¼ ìë™ ì¶”ì¶œí•©ë‹ˆë‹¤
        3. **ê²°ê³¼ í™•ì¸**: ì¶”ì¶œëœ ì •ë³´ë¥¼ í™”ë©´ì—ì„œ í™•ì¸í•©ë‹ˆë‹¤
        4. **ì—‘ì…€ ë‹¤ìš´ë¡œë“œ**: ë¶„ì„ ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        
        **ì§€ì› ì •ë³´:**
        - ë‹¨ì§€ëª… / ê³µê¸‰ìœ„ì¹˜
        - ì‹œí–‰ì‚¬ / ì‹œê³µì‚¬ / ë¶„ì–‘ëŒ€í–‰ì‚¬
        - ì²­ì•½ ì¼ì •
        - ì£¼íƒí˜•ë³„ ì„¸ëŒ€ìˆ˜
        - ë™/ì¸µë³„ ê³µê¸‰ê¸ˆì•¡í‘œ
        """)
