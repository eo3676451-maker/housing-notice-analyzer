# app.py íŒŒì¼ì˜ ìƒë‹¨ì— ì¶”ê°€ (ë‹¤ë¥¸ import ë¬¸ë“¤ ì•„ë˜)

from hs_app import extract_schedule_from_table, extract_company_from_table, extract_supply_target_from_tables

# ë˜ëŠ” í•„ìš”í•œ í•¨ìˆ˜ë§Œ ë”°ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:
# from hs_app_BI import extract_company_from_table

import fitz  # PyMuPDF
import tempfile
import streamlit as st
import pdfplumber
import re
from io import BytesIO
from datetime import datetime
import pandas as pd
from typing import Dict, List, Tuple
from collections import defaultdict

# ============================
#  ê³µí†µ ìœ í‹¸
# ============================
def parse_ymd(date_str: str):
    try:
        return datetime.strptime(date_str, "%Y.%m.%d").date()
    except:
        return None


# ============================
#  ë‹¨ì§€ëª… ì¶”ì¶œ
# ============================
def parse_complex_name(text: str):
    raw = None
    for line in text.splitlines():
        line = line.strip()
        if "ì…ì£¼ìëª¨ì§‘ê³µê³ " in line:
            raw = line.replace("ì…ì£¼ìëª¨ì§‘ê³µê³ ", "").strip()
            break

    if not raw:
        return None

    name = re.sub(r"\s+", " ", raw)
    name = name.strip(" ,Â·-")
    return name or None


# ============================
#  ê³µê¸‰ìœ„ì¹˜ ì¶”ì¶œ
# ============================
def parse_location(text: str):
    keywords = ["ê³µê¸‰ìœ„ì¹˜", "ì‚¬ì—…ìœ„ì¹˜", "ê±´ì„¤ìœ„ì¹˜", "ëŒ€ì§€ìœ„ì¹˜"]
    for line in text.splitlines():
        for key in keywords:
            if key in line:
                cleaned = line.replace(key, "")
                cleaned = cleaned.replace(":", "")
                cleaned = cleaned.replace("â– ", "")
                cleaned = cleaned.replace("ìœ„ì¹˜", "").strip()
                cleaned = re.sub(r"\s+", " ", cleaned)
                return cleaned
    return None


# ============================
#  ë¶ˆí•„ìš” ë¬¸ë‹¨(ìœ ì˜ì‚¬í•­Â·ë¬´ì£¼íƒê¸°ê°„ ë“±) ì œê±°
# ============================
def filter_irrelevant_sections(text: str) -> str:
    """
    ëª¨ì§‘ê³µê³  ì¤‘ 4~7, 11í•­ëª©ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ”
    'ìœ ì˜ì‚¬í•­/ë¬´ì£¼íƒê¸°ê°„ ì ìš©ê¸°ì¤€/ê¸°íƒ€ ì•ˆë‚´' ë“±ì€
    í•µì‹¬ì •ë³´ ì¶”ì¶œì— ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ë¶„ì„ í…ìŠ¤íŠ¸ì—ì„œ ì œê±°í•œë‹¤.
    """
    remove_keywords = [
        "ë¬´ì£¼íƒê¸°ê°„ ì ìš©ê¸°ì¤€",
        "ë¬´ì£¼íƒ ê¸°ê°„ ì ìš©ê¸°ì¤€",
        "ë¬´ì£¼íƒê¸°ê°„ ì‚°ì •ê¸°ì¤€",
        "ì²­ì•½ ì‹œ ìœ ì˜ì‚¬í•­",
        "ì²­ì•½ì‹œ ìœ ì˜ì‚¬í•­",
        "ìœ ì˜ì‚¬í•­",
        "ê¸°íƒ€ ì‚¬í•­",
        "ê¸°íƒ€ì‚¬í•­",
        "ê³µê¸‰(ë¶„ì–‘)ê³„ì•½ì— ê´€í•œ ìœ ì˜ì‚¬í•­",
        "ê³„ì•½ì²´ê²°ì‹œ ìœ ì˜ì‚¬í•­",
    ]

    filtered_lines = []
    for line in text.splitlines():
        s = line.strip()
        if any(k in s for k in remove_keywords):
            continue
        filtered_lines.append(line)

    return "\n".join(filtered_lines)


# ============================
#  íšŒì‚¬ëª… ì •ê·œí™” + íŒë³„ ìœ í‹¸
# ============================
def normalize_company_name(name: str) -> str:
    if not name:
        return ""
    name = str(name)

    name = name.replace("\n", " ")
    name = re.sub(r"\s+", " ", name).strip()

    name = name.lstrip("â€»*â€¢-Â·[]() ")

    name = name.replace(" (ì£¼)", "(ì£¼)").replace("(ì£¼) ", "(ì£¼)")
    name = name.replace(" ãˆœ", "ãˆœ").replace("ãˆœ ", "ãˆœ")

    if name.endswith("(ì£¼"):
        name = name + ")"
    if re.search(r"\(ì£¼$", name):
        name = name + ")"

    if "â€»" in name:
        name = name.split("â€»", 1)[0].strip()

    return name.strip()


COMPANY_HINT_KEYWORDS = [
    "ì¡°í•©", "ê±´ì„¤", "ì£¼ì‹íšŒì‚¬", "ãˆœ", "(ì£¼)", "ê°œë°œ",
    "ë””ì•¤ì”¨", "ë””ì—”ì”¨", "ì‚°ì—…", "ì—”ì§€ë‹ˆì–´ë§",
    "í™€ë”©ìŠ¤", "íˆ¬ì", "ê³µì‚¬", "ê¸°ì—…", "ì£¼íƒë„ì‹œ",
]


def looks_like_company(name: str) -> bool:
    if not name:
        return False
    name = name.strip()
    if len(name) > 30:
        return False

    bad_endings = ["ê¸°ì¤€", "ì ìš©ê¸°ì¤€", "ì ìš© ê¸°ì¤€", "ì‚°ì •ê¸°ì¤€"]
    if any(name.endswith(be) for be in bad_endings):
        return False

    strong_keywords = ["ì¡°í•©", "ê±´ì„¤", "ì£¼ì‹íšŒì‚¬", "ãˆœ", "(ì£¼)", "ê°œë°œ", "ê³µì‚¬", "ê¸°ì—…"]
    if "ê¸°ê°„" in name and not any(k in name for k in strong_keywords):
        return False

    if any(word in name for word in ["ê´‘ì—­ì‹œ", "íŠ¹ë³„ì‹œ", "ì‹œ ", "êµ° ", "êµ¬ ", "ë™ ", "ë¡œ ", "ê¸¸ "]):
        if not any(k in name for k in COMPANY_HINT_KEYWORDS):
            return False

    return any(k in name for k in COMPANY_HINT_KEYWORDS)


# ============================
#  í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹œí–‰/ì‹œê³µ/ë¶„ì–‘ ì¶”ì¶œ
# ============================
def extract_companies_from_text(text: str) -> Dict[str, List[str]]:
    result = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }

    norm = text.replace("ï¼š", ":")
    norm = re.sub(r"\s+", " ", norm)

    patterns = {
        "ì‹œí–‰ì‚¬": [
            r"(?:ì‚¬ì—…ì£¼ì²´|ì‹œí–‰ì|ì‹œí–‰ì‚¬)\s*[:]\s*([^\n:]+)",
        ],
        "ì‹œê³µì‚¬": [
            r"(?:ì‹œê³µì|ì‹œê³µì‚¬|ì‹œê³µ)\s*[:]\s*([^\n:]+)",
        ],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [
            r"(?:ë¶„ì–‘ëŒ€í–‰ì‚¬|ë¶„ì–‘ëŒ€í–‰|ë¶„ì–‘ëŒ€ë¦¬ì )\s*[:]\s*([^\n:]+)",
        ],
    }

    for role, pats in patterns.items():
        for pat in pats:
            for m in re.finditer(pat, norm):
                name = normalize_company_name(m.group(1))
                if looks_like_company(name) and name not in result[role]:
                    result[role].append(name)

    simple_patterns = {
        "ì‹œí–‰ì‚¬": [
            r"(?:ì‚¬ì—…ì£¼ì²´|ì‹œí–‰ì|ì‹œí–‰ì‚¬)\s+([^\n:]+)",
        ],
        "ì‹œê³µì‚¬": [
            r"(?:ì‹œê³µì|ì‹œê³µì‚¬|ì‹œê³µ)\s+([^\n:]+)",
        ],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [
            r"(?:ë¶„ì–‘ëŒ€í–‰ì‚¬|ë¶„ì–‘ëŒ€í–‰|ë¶„ì–‘ëŒ€ë¦¬ì )\s+([^\n:]+)",
        ],
    }

    for role, pats in simple_patterns.items():
        for pat in pats:
            for m in re.finditer(pat, norm):
                name = normalize_company_name(m.group(1))
                if looks_like_company(name) and name not in result[role]:
                    result[role].append(name)

    combo_pattern = r"(ì‹œí–‰|ì‹œê³µ|ë¶„ì–‘ëŒ€í–‰)\s*[: ]\s*([^/]+)"
    for m in re.finditer(combo_pattern, norm):
        key = m.group(1)
        name = normalize_company_name(m.group(2))
        if "ì‹œí–‰" in key:
            role = "ì‹œí–‰ì‚¬"
        elif "ì‹œê³µ" in key:
            role = "ì‹œê³µì‚¬"
        else:
            role = "ë¶„ì–‘ëŒ€í–‰ì‚¬"
        if looks_like_company(name) and name not in result[role]:
            result[role].append(name)

    return result


# ============================
#  í•µì‹¬ ì •ë³´(ê³µê¸‰ê·œëª¨ + í…ìŠ¤íŠ¸ ë°±ì—…ìš© ì‹œí–‰/ì‹œê³µ) ì¶”ì¶œ
# ============================
def extract_core_info(text: str):
    info = {
        "ê³µê¸‰ê·œëª¨": None,
        "ì‹œí–‰ì‚¬": None,
        "ì‹œê³µì‚¬": None,
    }

    for line in text.splitlines():
        s = line.strip()
        if not s:
            continue

        if not info["ê³µê¸‰ê·œëª¨"] and ("ê³µê¸‰ê·œëª¨" in s or "ì´ ê³µê¸‰ì„¸ëŒ€ìˆ˜" in s):
            cleaned = s
            cleaned = cleaned.replace("â– ", "")
            cleaned = cleaned.replace("â—", "")
            cleaned = cleaned.replace("ê³µê¸‰ê·œëª¨", "")
            cleaned = cleaned.replace("ì´ ê³µê¸‰ì„¸ëŒ€ìˆ˜", "")
            cleaned = cleaned.replace(":", "")
            cleaned = cleaned.strip()
            info["ê³µê¸‰ê·œëª¨"] = cleaned
            continue

        if not info["ì‹œí–‰ì‚¬"] and ("ì‹œí–‰ì" in s or "ì‹œí–‰ì‚¬" in s):
            cleaned = s
            cleaned = cleaned.replace("â– ", "").replace("â—", "")
            cleaned = cleaned.replace("ì‹œí–‰ì", "").replace("ì‹œí–‰ì‚¬", "")
            cleaned = cleaned.replace(":", "")
            cleaned = cleaned.strip()

            cleaned = normalize_company_name(cleaned)
            if looks_like_company(cleaned):
                info["ì‹œí–‰ì‚¬"] = cleaned
            continue

        if not info["ì‹œê³µì‚¬"] and ("ì‹œê³µì" in s or "ì‹œê³µì‚¬" in s):
            cleaned = s
            cleaned = cleaned.replace("â– ", "").replace("â—", "")
            cleaned = cleaned.replace("ì‹œê³µì", "").replace("ì‹œê³µì‚¬", "")
            cleaned = cleaned.replace(":", "")
            cleaned = cleaned.strip()

            cleaned = normalize_company_name(cleaned)
            if looks_like_company(cleaned):
                info["ì‹œê³µì‚¬"] = cleaned
            continue

    return info


# ============================
#  ì…ì£¼ ì˜ˆì •ì¼ ì¶”ì¶œ
# ============================
def extract_move_in_date(text: str) -> str | None:
    candidate_lines: List[str] = []

    for line in text.splitlines():
        s = line.strip()
        if not s:
            continue

        no_space = s.replace(" ", "")

        if any(k in no_space for k in ["ì…ì£¼ì‹œê¸°", "ì…ì£¼ì‹œê¸°", "ì…ì£¼ì˜ˆì •", "ì…ì£¼ì˜ˆì •ì¼"]):
            candidate_lines.append(s)

    for s in candidate_lines:
        m = re.search(r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”", s)
        if m:
            year = int(m.group(1))
            month = int(m.group(2))
            return f"{year}ë…„ {month}ì›”"

        m2 = re.search(r"(\d{4})\.(\d{1,2})", s)
        if m2:
            year = int(m2.group(1))
            month = int(m2.group(2))
            return f"{year}ë…„ {month}ì›”"

    if candidate_lines:
        first = candidate_lines[0]
        return first[:40] + "..." if len(first) > 40 else first

    return None


# ============================
#  í‘œ ê¸°ë°˜ íšŒì‚¬ì •ë³´ ì¶”ì¶œ ìœ í‹¸
# ============================
ROLE_KEYWORDS = {
    "ì‹œí–‰ì‚¬": ["ì‚¬ì—…ì£¼ì²´", "ì‹œí–‰ì", "ì‹œí–‰ì‚¬", "ì‚¬ì—…ì‹œí–‰ì"],
    "ì‹œê³µì‚¬": ["ì‹œê³µì‚¬", "ì‹œê³µì", "ì‹œê³µ"],
    "ë¶„ì–‘ëŒ€í–‰ì‚¬": ["ë¶„ì–‘ëŒ€í–‰ì‚¬", "ë¶„ì–‘ëŒ€í–‰", "ë¶„ì–‘ëŒ€ë¦¬ì ", "ìœ„íƒì‚¬"],
}


def detect_role_from_header(text: str) -> List[str]:
    roles = []
    t = text.replace(" ", "")
    for role, keywords in ROLE_KEYWORDS.items():
        if any(k in t for k in keywords):
            roles.append(role)
    return roles


def extract_from_vertical_label_table(
    df: pd.DataFrame,
    page_idx: int,
) -> Dict[str, List[Tuple[str, int]]]:
    res = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }
    if df.empty:
        return res

    df = df.fillna("")
    label_col = df.iloc[:, 0].astype(str)

    for i, label in enumerate(label_col):
        roles = detect_role_from_header(label)
        if not roles:
            continue
        row = df.iloc[i, 1:]
        candidates = [normalize_company_name(v) for v in row if str(v).strip()]
        for role in roles:
            for c in candidates:
                if looks_like_company(c):
                    res[role].append((c, page_idx))

    return res


def extract_from_horizontal_header_table(
    df: pd.DataFrame,
    page_idx: int,
) -> Dict[str, List[Tuple[str, int]]]:
    res = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }
    if df.empty or len(df) < 2:
        return res

    df = df.fillna("")
    header = df.iloc[0].astype(str).tolist()
    body = df[1:]

    for col_idx, h in enumerate(header):
        roles = detect_role_from_header(h)
        if not roles:
            continue
        col_values = body.iloc[:, col_idx].astype(str)
        candidates = [
            normalize_company_name(v)
            for v in col_values
            if str(v).strip()
        ]
        for role in roles:
            for c in candidates:
                if looks_like_company(c):
                    res[role].append((c, page_idx))

    return res


def extract_company_candidates_from_pdf(pdf) -> Tuple[Dict[str, List[Tuple[str, int]]], int]:
    result = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }

    last_page_idx = len(pdf.pages) - 1 if pdf.pages else 0

    for page_idx, page in enumerate(pdf.pages):
        tables = page.extract_tables() or []
        for table in tables:
            if not table:
                continue
            df = pd.DataFrame(table)
            if df.empty:
                continue

            vertical = extract_from_vertical_label_table(df, page_idx)
            horizontal = extract_from_horizontal_header_table(df, page_idx)

            for role in result.keys():
                result[role].extend(vertical.get(role, []))
                result[role].extend(horizontal.get(role, []))

    return result, last_page_idx


def choose_final_company(
    text_candidates: Dict[str, List[str]],
    table_candidates: Dict[str, List[Tuple[str, int]]],
    last_page_idx: int = None,
) -> Dict[str, str]:
    scores: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))

    for role, vals in table_candidates.items():
        for name, page_idx in vals:
            if not name:
                continue
            base = 3
            bonus = 0
            if last_page_idx is not None and page_idx == last_page_idx:
                bonus += 2
            scores[role][name] += base + bonus

    for role, names in text_candidates.items():
        for name in names:
            if not name:
                continue
            scores[role][name] += 2

    final = {
        "ì‹œí–‰ì‚¬": "",
        "ì‹œê³µì‚¬": "",
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": "",
    }

    for role, name_scores in scores.items():
        if not name_scores:
            continue
        sorted_candidates = sorted(
            name_scores.items(),
            key=lambda x: (x[1], len(x[0])),
            reverse=True,
        )
        final[role] = sorted_candidates[0][0]

    return final


# ============================
#  í…ìŠ¤íŠ¸ + í‘œ ê¸°ë°˜ í†µí•© ì¶”ì¶œ
# ============================
def extract_company_from_table(pdf, text: str) -> Dict[str, str]:
    text_candidates = extract_companies_from_text(text)
    table_candidates, last_page_idx = extract_company_candidates_from_pdf(pdf)
    final = choose_final_company(text_candidates, table_candidates, last_page_idx)
    return final


# ============================
#  ì¤‘ë„ê¸ˆ ëŒ€ì¶œ ì¡°ê±´ ì¶”ì¶œ
# ============================
def extract_loan_condition(text: str):
    condition = None
    related_lines = []

    for line in text.splitlines():
        s = line.strip()
        if "ì¤‘ë„ê¸ˆ" in s and "ëŒ€ì¶œ" in s:
            related_lines.append(s)
        elif "ì¤‘ë„ê¸ˆ" in s and "ì´ì" in s:
            related_lines.append(s)

    joined = " ".join(related_lines)

    if "ì´ìí›„ë¶ˆì œ" in joined or "ì´ì í›„ë¶ˆì œ" in joined:
        condition = "ì´ìí›„ë¶ˆì œ"
    elif "ë¬´ì´ì" in joined:
        condition = "ë¬´ì´ì"

    if not condition and joined:
        condition = joined

    return condition


# ============================
#  ì—‘ì…€ ë‹¤ìš´ë¡œë“œìš© íŒŒì¼ ìƒì„±
# ============================
def make_excel_file(
    complex_name: str,
    location: str,
    core: dict,
    move_in: str | None,
    final_siheng: str | None,
    final_sigong: str | None,
    final_agency: str | None,
    loan_cond: str | None,
    schedule_rows: list,
    supply_rows: list,
    price_rows: list,
) -> BytesIO:
    summary_rows = [
        {"í•­ëª©": "ë‹¨ì§€ëª…", "ê°’": complex_name},
        {"í•­ëª©": "ê³µê¸‰ìœ„ì¹˜", "ê°’": location},
        {"í•­ëª©": "ê³µê¸‰ê·œëª¨", "ê°’": core.get("ê³µê¸‰ê·œëª¨") or ""},
        {"í•­ëª©": "ì…ì£¼ì˜ˆì •ì¼", "ê°’": move_in or ""},
        {"í•­ëª©": "ì‹œí–‰ì‚¬", "ê°’": final_siheng or ""},
        {"í•­ëª©": "ì‹œê³µì‚¬", "ê°’": final_sigong or ""},
        {"í•­ëª©": "ë¶„ì–‘ëŒ€í–‰ì‚¬", "ê°’": final_agency or ""},
        {"í•­ëª©": "ì¤‘ë„ê¸ˆ ëŒ€ì¶œ ì¡°ê±´", "ê°’": loan_cond or ""},
    ]

    for row in schedule_rows:
        summary_rows.append({"í•­ëª©": row.get("í•­ëª©", ""), "ê°’": row.get("ì¼ì •", "")})

    df_summary = pd.DataFrame(summary_rows)
    df_supply = pd.DataFrame(supply_rows) if supply_rows else pd.DataFrame()
    df_price = pd.DataFrame(price_rows) if price_rows else pd.DataFrame()

    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        sheet_name = "ëª¨ì§‘ê³µê³ "

        df_summary.to_excel(writer, index=False, sheet_name=sheet_name, startrow=0)

        start_row = len(df_summary) + 2

        if not df_supply.empty:
            df_supply.to_excel(writer, index=False, sheet_name=sheet_name, startrow=start_row)
            start_row += len(df_supply) + 2

        if not df_price.empty:
            df_price.to_excel(writer, index=False, sheet_name=sheet_name, startrow=start_row)

    output.seek(0)
    return output


# ============================
#  í‘œì—ì„œ ì²­ì•½ ì¼ì • ì¶”ì¶œ
# ============================
def extract_schedule_from_table(pdf):
    schedule = {
        "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼": None,
        "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼": None,
        "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼": None,
        "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼": None,
        "ë‹¹ì²¨ìë°œí‘œì¼": None,
        "ì„œë¥˜ì ‘ìˆ˜": None,
        "ê³„ì•½ì²´ê²°": None,
    }

    header_map = {
        "ì…ì£¼ìëª¨ì§‘ê³µê³ ": "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "ì…ì£¼ì ëª¨ì§‘ê³µê³ ": "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "íŠ¹ë³„ê³µê¸‰ì ‘ìˆ˜": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "íŠ¹ë³„ê³µê¸‰ ì‹ ì²­": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "1ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "1ìˆœìœ„": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "2ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "2ìˆœìœ„": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ë‹¹ì²¨ìë°œí‘œì¼": "ë‹¹ì²¨ìë°œí‘œì¼",
        "ë‹¹ì²¨ì ë°œí‘œ": "ë‹¹ì²¨ìë°œí‘œì¼",
        "ì„œë¥˜ì ‘ìˆ˜": "ì„œë¥˜ì ‘ìˆ˜",
        "ì •ë‹¹ê³„ì•½": "ê³„ì•½ì²´ê²°",
        "ê³„ì•½ì²´ê²°": "ê³„ì•½ì²´ê²°",
    }

    date_pattern = r"\d{4}\.\d{1,2}\.\d{1,2}"

    def update(label, new_val):
        old = schedule.get(label)
        if not old:
            schedule[label] = new_val
            return

        try:
            old_d = datetime.strptime(re.findall(date_pattern, old)[0], "%Y.%m.%d")
            new_d = datetime.strptime(re.findall(date_pattern, new_val)[0], "%Y.%m.%d")
            if new_d > old_d:
                schedule[label] = new_val
        except:
            pass

    for page in pdf.pages:
        tables = page.extract_tables() or []

        for table in tables:
            if not table:
                continue

            rows = table

            for r, row in enumerate(rows):
                for c, cell in enumerate(row):
                    if not cell:
                        continue
                    cell_t = cell.replace(" ", "")

                    for key, label in header_map.items():
                        if key.replace(" ", "") in cell_t:

                            for rr in range(r + 1, len(rows)):
                                if c >= len(rows[rr]):
                                    continue

                                raw = rows[rr][c] or ""
                                found = re.findall(date_pattern, raw)
                                if not found:
                                    continue

                                if label in ["ì„œë¥˜ì ‘ìˆ˜", "ê³„ì•½ì²´ê²°"] and len(found) >= 2:
                                    update(label, f"{found[0]} ~ {found[-1]}")
                                else:
                                    update(label, found[0])

                                break

    return schedule


# ============================
#  ê³µê¸‰ëŒ€ìƒ(íƒ€ì…ë³„) ì¶”ì¶œ
# ============================
def extract_supply_target_from_tables(pdf) -> List[Dict[str, str]]:
    results: List[Dict[str, str]] = []

    for page in pdf.pages:
        tables = page.extract_tables() or []
        for table in tables:
            if not table or len(table) < 3:
                continue

            df = pd.DataFrame(table).fillna("")
            header_idx = None

            for i, row in df.iterrows():
                row_txt = "".join(str(x) for x in row.tolist())
                if "ì£¼íƒí˜•" in row_txt and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹ í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt):
                    header_idx = i
                    break

            if header_idx is None:
                continue

            df2 = df.iloc[header_idx:].reset_index(drop=True)
            ncols = df2.shape[1]

            col_map: Dict[str, int] = {}
            for c in range(ncols):
                hdr = "".join(df2.iloc[0:4, c].astype(str).tolist())
                hdr = hdr.replace(" ", "").replace("\n", "")

                if "ì£¼íƒí˜•" in hdr:
                    col_map["ì£¼íƒí˜•"] = c
                elif "ì•½ì‹í‘œê¸°" in hdr or "ì•½ì‹í‘œì‹œ" in hdr or "ì•½ì‹" in hdr:
                    col_map["ì•½ì‹í‘œê¸°"] = c
                elif "ì£¼ê±°ì „ìš©ë©´ì " in hdr or ("ì „ìš©" in hdr and "ë©´ì " in hdr):
                    col_map["ì£¼ê±° ì „ìš©ë©´ì "] = c
                elif "ì†Œê³„" in hdr and "ì„¸ëŒ€" not in hdr:
                    col_map["ì£¼íƒê³µê¸‰ë©´ì  ì†Œê³„"] = c
                elif ("ì´ê³µê¸‰" in hdr and "ì„¸ëŒ€ìˆ˜" in hdr) or "ì´ê³µê¸‰ì„¸ëŒ€ìˆ˜" in hdr:
                    col_map["ì´ ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = c
                elif "ì¼ë°˜ê³µê¸‰" in hdr and "ì„¸ëŒ€ìˆ˜" in hdr:
                    col_map["ì¼ë°˜ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = c
                elif "ê¸°ê´€ì¶”ì²œ" in hdr:
                    col_map["ê¸°ê´€ì¶”ì²œ"] = c
                elif "ë‹¤ìë…€" in hdr:
                    col_map["ë‹¤ìë…€ê°€êµ¬"] = c
                elif "ì‹ í˜¼ë¶€ë¶€" in hdr:
                    col_map["ì‹ í˜¼ë¶€ë¶€"] = c
                elif "ë…¸ë¶€ëª¨" in hdr:
                    col_map["ë…¸ë¶€ëª¨ë¶€ì–‘"] = c
                elif "ìƒì• ìµœì´ˆ" in hdr:
                    col_map["ìƒì• ìµœì´ˆ"] = c

            if not col_map:
                continue

            for r in range(1, df2.shape[0]):
                row = df2.iloc[r]
                row_txt = "".join(str(x) for x in row.tolist())

                if "í•©ê³„" in row_txt:
                    continue

                def get_val(key: str) -> str:
                    idx = col_map.get(key)
                    if idx is None or idx >= len(row):
                        return ""
                    return str(row.iloc[idx]).strip()

                rec: Dict[str, str] = {}
                rec["ì£¼íƒí˜•"] = get_val("ì£¼íƒí˜•")
                rec["ì•½ì‹í‘œê¸°"] = get_val("ì•½ì‹í‘œê¸°")
                rec["ì£¼ê±° ì „ìš©ë©´ì "] = get_val("ì£¼ê±° ì „ìš©ë©´ì ")
                rec["ì£¼íƒê³µê¸‰ë©´ì  ì†Œê³„"] = get_val("ì£¼íƒê³µê¸‰ë©´ì  ì†Œê³„")
                rec["ì´ ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = get_val("ì´ ê³µê¸‰ ì„¸ëŒ€ìˆ˜")
                rec["ì¼ë°˜ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = get_val("ì¼ë°˜ê³µê¸‰ ì„¸ëŒ€ìˆ˜")

                special_total = 0
                for k in ["ê¸°ê´€ì¶”ì²œ", "ë‹¤ìë…€ê°€êµ¬", "ì‹ í˜¼ë¶€ë¶€", "ë…¸ë¶€ëª¨ë¶€ì–‘", "ìƒì• ìµœì´ˆ"]:
                    idx = col_map.get(k)
                    if idx is None or idx >= len(row):
                        continue
                    raw = str(row.iloc[idx])
                    num = re.sub(r"[^0-9]", "", raw)
                    if num:
                        special_total += int(num)

                rec["íŠ¹ë³„ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = str(special_total) if special_total > 0 else ""

                if not (rec.get("ì£¼íƒí˜•") or rec.get("ì•½ì‹í‘œê¸°")):
                    continue
                if ("ì£¼íƒí˜•" in rec.get("ì£¼íƒí˜•", "")) or ("ì•½ì‹" in rec.get("ì•½ì‹í‘œê¸°", "")):
                    continue

                results.append(rec)

            # íƒ€ì…í‘œëŠ” í•œ ë²ˆë§Œ ì°¾ìœ¼ë©´ ì¶©ë¶„í•˜ë‹ˆ, ì²« ë°œê²¬ í›„ ì¢…ë£Œ
            if results:
                return results

    return results


# ============================
#  ê³µê¸‰ê¸ˆì•¡í‘œ ì¶”ì¶œ (ë™Â·í˜¸Â·ì¸µë³„, ì „ì²´ íƒ€ì…)
# ============================
def extract_price_table_from_tables(pdf) -> List[Dict[str, str]]:
    """
    'ê³µê¸‰ê¸ˆì•¡í‘œ'ì—ì„œ
    - ì£¼íƒí˜•
    - ì•½ì‹í‘œê¸°
    - ë™/í˜¸ë³„
    - ì¸µêµ¬ë¶„
    - í•´ë‹¹ì„¸ëŒ€ìˆ˜
    - ê³µê¸‰ê¸ˆì•¡ ì†Œê³„
    ë¥¼ ë½‘ì•„ì˜¨ë‹¤.

    ì „ëµ
    1) ì˜µì…˜/ì„ íƒì‚¬ì–‘ í‘œëŠ” ì œì™¸
    2) í—¤ë”ì—ì„œ ì£¼íƒí˜•/ì•½ì‹/ë™í˜¸/ì¸µ/ì„¸ëŒ€ìˆ˜ ìœ„ì¹˜ë§Œ ëŒ€ëµ ì¡ê³ ,
       ê³µê¸‰ê¸ˆì•¡ ì†Œê³„ëŠ” ê° í–‰ì—ì„œ "ê°€ì¥ í° ê¸ˆì•¡"ì„ ì„ íƒ
    3) ì„¸ëŒ€ìˆ˜ëŠ” 4ìë¦¬(1000ì„¸ëŒ€) ì´ìƒì´ë©´ ì˜ëª» ì¸ì‹ëœ ê¸ˆì•¡ìœ¼ë¡œ ë³´ê³  ë²„ë¦°ë‹¤.
    """

    results: List[Dict[str, str]] = []

    last_col_map: Dict[str, int] | None = None
    current_type = ""
    current_abbr = ""
    current_dongho = ""

    def is_floor_like(s: str) -> bool:
        if not s:
            return False
        s2 = s.replace(" ", "")
        return ("ì¸µ" in s2) and not ("ë™" in s2 or "í˜¸" in s2)

    for page_idx, page in enumerate(pdf.pages):
        tables = page.extract_tables() or []
        for table_idx, table in enumerate(tables):
            if not table or len(table) < 2:
                continue

            df = pd.DataFrame(table).fillna("")
            all_txt = "".join(df.astype(str).values.ravel()).replace(" ", "")

            # 1) ì˜µì…˜/ì„ íƒì‚¬ì–‘ í‘œëŠ” í†µì§¸ë¡œ ìŠ¤í‚µ
            if any(k in all_txt for k in ["ì˜µì…˜", "ì„ íƒí’ˆëª©", "ì„ íƒì‚¬ì–‘"]):
                continue

            # 2) ê³µê¸‰ê¸ˆì•¡í‘œ í›„ë³´ í•„í„°
            has_price_word = ("ê³µê¸‰ê¸ˆì•¡" in all_txt) or ("ë¶„ì–‘ê¸ˆì•¡" in all_txt)
            has_dongho = ("ë™" in all_txt and "í˜¸" in all_txt) or "ë™/í˜¸" in all_txt
            has_floor = "ì¸µêµ¬ë¶„" in all_txt or ("ì¸µ" in all_txt and "êµ¬ë¶„" in all_txt)
            has_haedang = "í•´ë‹¹ì„¸ëŒ€" in all_txt

            if not has_price_word:
                continue
            if not (has_dongho or has_floor or has_haedang):
                continue

            # ---------- A. ì™„ì „í•œ í—¤ë”(ì£¼íƒí˜•+ì•½ì‹í‘œê¸°) ì°¾ê¸° ----------
            header_idx = None
            for i, row in df.iterrows():
                row_txt = "".join(str(x) for x in row.tolist())
                if (
                    "ì£¼íƒí˜•" in row_txt
                    and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹ í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt)
                ):
                    header_idx = i
                    break

            col_map: Dict[str, int] = {}

            if header_idx is not None:
                df2 = df.iloc[header_idx:].reset_index(drop=True)
                ncols = df2.shape[1]

                for c in range(ncols):
                    hdr = "".join(df2.iloc[0:4, c].astype(str).tolist())
                    hdr = hdr.replace(" ", "").replace("\n", "")

                    if "ì£¼íƒí˜•" in hdr:
                        col_map["ì£¼íƒí˜•"] = c
                    elif "ì•½ì‹í‘œê¸°" in hdr or "ì•½ì‹í‘œì‹œ" in hdr or "ì•½ì‹" in hdr:
                        col_map["ì•½ì‹í‘œê¸°"] = c
                    elif ("ë™" in hdr and "í˜¸" in hdr) or "ë™/í˜¸" in hdr:
                        col_map["ë™/í˜¸ë³„"] = c
                    elif "ì¸µêµ¬ë¶„" in hdr or ("ì¸µ" in hdr and "êµ¬ë¶„" in hdr):
                        col_map["ì¸µêµ¬ë¶„"] = c
                    elif "í•´ë‹¹ì„¸ëŒ€ìˆ˜" in hdr or "í•´ë‹¹ì„¸ëŒ€" in hdr:
                        col_map["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] = c

                last_col_map = col_map.copy()

            else:
                # ---------- B. í—¤ë” ì—†ëŠ” ì´ì–´ì§€ëŠ” í‘œ(7~9í˜ì´ì§€) ----------
                if not last_col_map:
                    continue

                df2 = df.reset_index(drop=True)
                col_map = last_col_map.copy()

                # ìƒë‹¨ ëª‡ ì¤„ì„ ìŠ¤ìº”í•´ ë™/ì¸µ/ì„¸ëŒ€ ìœ„ì¹˜ ë³´ì •
                tmp_map: Dict[str, int] = {}
                max_head_rows = min(5, df2.shape[0])

                for c in range(df2.shape[1]):
                    pieces = []
                    for r_head in range(max_head_rows):
                        pieces.append(str(df2.iloc[r_head, c]))
                    hdr = "".join(pieces).replace(" ", "").replace("\n", "")

                    if ("ë™" in hdr and "í˜¸" in hdr) or "ë™/í˜¸" in hdr:
                        tmp_map["ë™/í˜¸ë³„"] = c
                    elif "ì¸µêµ¬ë¶„" in hdr or ("ì¸µ" in hdr and "êµ¬ë¶„" in hdr):
                        tmp_map["ì¸µêµ¬ë¶„"] = c
                    elif "í•´ë‹¹ì„¸ëŒ€ìˆ˜" in hdr or "í•´ë‹¹ì„¸ëŒ€" in hdr:
                        tmp_map["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] = c

                col_map.update(tmp_map)

            if not col_map:
                continue

            # ---------------------- ë°ì´í„° í–‰ íŒŒì‹± ----------------------
            start_row = 1 if header_idx is not None else 0

            for r in range(start_row, df2.shape[0]):
                row = df2.iloc[r]
                row_txt = "".join(str(x) for x in row.tolist())

                if "ì£¼íƒí˜•" in row_txt and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt):
                    continue
                if "í•©ê³„" in row_txt or "ì „íƒ€ì…" in row_txt or "ë¶€ë¶„" in row_txt:
                    continue


# ============================
#  ê³µê¸‰ê¸ˆì•¡í‘œ ì¶”ì¶œ (ë™Â·í˜¸Â·ì¸µë³„, ì „ì²´ íƒ€ì…)
# ============================
def extract_price_table_from_tables(pdf) -> List[Dict[str, str]]:
    """
    'ê³µê¸‰ê¸ˆì•¡í‘œ'ì—ì„œ
    - ì£¼íƒí˜•
    - ì•½ì‹í‘œê¸°
    - ë™/í˜¸ë³„
    - ì¸µêµ¬ë¶„
    - í•´ë‹¹ì„¸ëŒ€ìˆ˜
    - ê³µê¸‰ê¸ˆì•¡ ì†Œê³„
    ë¥¼ ë½‘ì•„ì˜¨ë‹¤.

    ì „ëµ
    1) ì˜µì…˜/ì„ íƒì‚¬ì–‘ í‘œëŠ” ì œì™¸
    2) í—¤ë”ì—ì„œ ì£¼íƒí˜•/ì•½ì‹/ë™í˜¸/ì¸µ/ì„¸ëŒ€ìˆ˜ ìœ„ì¹˜ë§Œ ëŒ€ëµ ì¡ê³ ,
       ê³µê¸‰ê¸ˆì•¡ ì†Œê³„ëŠ” ê° í–‰ì—ì„œ "ê°€ì¥ í° ê¸ˆì•¡"ì„ ì„ íƒ
    3) (ì£¼íƒí˜•, ì•½ì‹í‘œê¸°, ë™/í˜¸ë³„, ì¸µêµ¬ë¶„) ì´ ê°™ì€ í–‰ë“¤ ì¤‘ì—ì„œ
       ê³µê¸‰ê¸ˆì•¡ ì†Œê³„ê°€ ê°€ì¥ í° í•œ í–‰ë§Œ ìµœì¢… ê²°ê³¼ì— ë‚¨ê¸´ë‹¤.
    """

    results: List[Dict[str, str]] = []

    last_col_map: Dict[str, int] | None = None
    current_type = ""
    current_abbr = ""
    current_dongho = ""

    def is_floor_like(s: str) -> bool:
        if not s:
            return False
        s2 = s.replace(" ", "")
        return ("ì¸µ" in s2) and not ("ë™" in s2 or "í˜¸" in s2)

    for page_idx, page in enumerate(pdf.pages):
        tables = page.extract_tables() or []
        for table_idx, table in enumerate(tables):
            if not table or len(table) < 2:
                continue

            df = pd.DataFrame(table).fillna("")
            all_txt = "".join(df.astype(str).values.ravel()).replace(" ", "")

            # 1) ì˜µì…˜/ì„ íƒì‚¬ì–‘ í‘œëŠ” í†µì§¸ë¡œ ìŠ¤í‚µ
            if any(k in all_txt for k in ["ì˜µì…˜", "ì„ íƒí’ˆëª©", "ì„ íƒì‚¬ì–‘"]):
                continue

            # 2) ê³µê¸‰ê¸ˆì•¡í‘œ í›„ë³´ í•„í„°
            has_price_word = ("ê³µê¸‰ê¸ˆì•¡" in all_txt) or ("ë¶„ì–‘ê¸ˆì•¡" in all_txt)
            has_dongho = ("ë™" in all_txt and "í˜¸" in all_txt) or "ë™/í˜¸" in all_txt
            has_floor = "ì¸µêµ¬ë¶„" in all_txt or ("ì¸µ" in all_txt and "êµ¬ë¶„" in all_txt)
            has_haedang = "í•´ë‹¹ì„¸ëŒ€" in all_txt

            if not has_price_word:
                # ê³µê¸‰ê¸ˆì•¡ ê´€ë ¨ ë‹¨ì–´ê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ í‘œì¼ ê°€ëŠ¥ì„±ì´ í¼
                continue
            if not (has_dongho or has_floor or has_haedang):
                continue

            # ---------------- A. ì™„ì „í•œ í—¤ë”(ì£¼íƒí˜•+ì•½ì‹í‘œê¸°) íƒìƒ‰ ----------------
            header_idx = None
            for i, row in df.iterrows():
                row_txt = "".join(str(x) for x in row.tolist())
                if (
                    "ì£¼íƒí˜•" in row_txt
                    and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹ í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt)
                ):
                    header_idx = i
                    break

            col_map: Dict[str, int] = {}

            if header_idx is not None:
                df2 = df.iloc[header_idx:].reset_index(drop=True)
                ncols = df2.shape[1]

                for c in range(ncols):
                    hdr = "".join(df2.iloc[0:4, c].astype(str).tolist())
                    hdr = hdr.replace(" ", "").replace("\n", "")

                    if "ì£¼íƒí˜•" in hdr:
                        col_map["ì£¼íƒí˜•"] = c
                    elif "ì•½ì‹í‘œê¸°" in hdr or "ì•½ì‹í‘œì‹œ" in hdr or "ì•½ì‹" in hdr:
                        col_map["ì•½ì‹í‘œê¸°"] = c
                    elif ("ë™" in hdr and "í˜¸" in hdr) or "ë™/í˜¸" in hdr:
                        col_map["ë™/í˜¸ë³„"] = c
                    elif "ì¸µêµ¬ë¶„" in hdr or ("ì¸µ" in hdr and "êµ¬ë¶„" in hdr):
                        col_map["ì¸µêµ¬ë¶„"] = c
                    elif "í•´ë‹¹ì„¸ëŒ€ìˆ˜" in hdr or "í•´ë‹¹ì„¸ëŒ€" in hdr:
                        col_map["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] = c

                last_col_map = col_map.copy()

            else:
                # ------------- B. í—¤ë” ì—†ëŠ” ì´ì–´ì§€ëŠ” í‘œ(7~9í˜ì´ì§€) -------------
                if not last_col_map:
                    continue

                df2 = df.reset_index(drop=True)
                ncols = df2.shape[1]

                col_map = last_col_map.copy()

                # ìƒë‹¨ ëª‡ ì¤„ì„ ìŠ¤ìº”í•´ ë™/ì¸µ/ì„¸ëŒ€ ìœ„ì¹˜ë§Œ ë³´ì •
                tmp_map: Dict[str, int] = {}
                max_head_rows = min(5, df2.shape[0])

                for c in range(ncols):
                    pieces = []
                    for r_head in range(max_head_rows):
                        pieces.append(str(df2.iloc[r_head, c]))
                    hdr = "".join(pieces).replace(" ", "").replace("\n", "")

                    if ("ë™" in hdr and "í˜¸" in hdr) or "ë™/í˜¸" in hdr:
                        tmp_map["ë™/í˜¸ë³„"] = c
                    elif "ì¸µêµ¬ë¶„" in hdr or ("ì¸µ" in hdr and "êµ¬ë¶„" in hdr):
                        tmp_map["ì¸µêµ¬ë¶„"] = c
                    elif "í•´ë‹¹ì„¸ëŒ€ìˆ˜" in hdr or "í•´ë‹¹ì„¸ëŒ€" in hdr:
                        tmp_map["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] = c

                col_map.update(tmp_map)
                df2 = df2  # ì´ë¦„ ë§ì¶”ê¸°ìš©

            if not col_map:
                continue

            # ---------------------- ë°ì´í„° í–‰ íŒŒì‹± ----------------------
            start_row = 1 if header_idx is not None else 0

            for r in range(start_row, df2.shape[0]):
                row = df2.iloc[r]
                row_txt = "".join(str(x) for x in row.tolist())

                if "ì£¼íƒí˜•" in row_txt and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt):
                    continue
                if "í•©ê³„" in row_txt or "ì „íƒ€ì…" in row_txt or "ë¶€ë¶„" in row_txt:
                    continue

                def get_val_idx(row, idx: int | None) -> str:
                    if idx is None or idx < 0 or idx >= len(row):
                        return ""
                    return str(row.iloc[idx]).strip()

                # ì£¼íƒí˜• / ì•½ì‹í‘œê¸°
                idx_type = col_map.get("ì£¼íƒí˜•")
                v_type = get_val_idx(row, idx_type)
                if v_type:
                    current_type = v_type

                idx_abbr = col_map.get("ì•½ì‹í‘œê¸°")
                v_abbr = get_val_idx(row, idx_abbr)
                if v_abbr:
                    current_abbr = v_abbr

                # ë™/í˜¸ / ì¸µ ì²˜ë¦¬
                idx_dongho = col_map.get("ë™/í˜¸ë³„")
                raw_dongho = get_val_idx(row, idx_dongho)

                floor_val = get_val_idx(row, col_map.get("ì¸µêµ¬ë¶„"))

                if raw_dongho:
                    if is_floor_like(raw_dongho):
                        # ë™/í˜¸ ì¹¸ì— ì¸µ ì •ë³´ê°€ ë“¤ì–´ì˜¨ ê²½ìš° â†’ ë™/í˜¸ëŠ” ì´ì „ê°’ ìœ ì§€, ì¸µìœ¼ë¡œ ì‚¬ìš©
                        if not is_floor_like(floor_val):
                            floor_val = raw_dongho
                    else:
                        current_dongho = raw_dongho

                # ì¸µêµ¬ë¶„ì— 'ì¸µ' ê¸€ìê°€ ë¹ ì¡Œìœ¼ë©´ ë³´ì •
                if floor_val:
                    fv = floor_val.replace(" ", "")
                    if ("ì¸µ" not in fv) and re.search(r"\d", fv):
                        floor_val = fv + "ì¸µ"

                # ì„¸ëŒ€ìˆ˜
                haedang_val = get_val_idx(row, col_map.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜"))
                # ë„ˆë¬´ í° ìˆ«ìëŠ” ì„¸ëŒ€ìˆ˜ë¡œ ë³´ê¸° ì–´ë ¤ìš°ë¯€ë¡œ ë²„ë¦¼
                hae_digits = re.sub(r"[^0-9]", "", haedang_val or "")
                if hae_digits and len(hae_digits) > 3:  # 999ì„¸ëŒ€ ì´ˆê³¼ë©´ ì´ìƒì¹˜ë¡œ ì²˜ë¦¬
                    haedang_val = ""

                # ----- ê³µê¸‰ê¸ˆì•¡ ì†Œê³„: í–‰ì˜ ìš°ì¸¡ ë¶€ë¶„ì—ì„œ ê°€ì¥ í° ê¸ˆì•¡ ì„ íƒ -----
                # ì‹œì‘ ì¸ë±ìŠ¤: ì„¸ëŒ€ìˆ˜ ë‹¤ìŒ ì»¬ëŸ¼ ë˜ëŠ” ì¸µêµ¬ë¶„ ë‹¤ìŒ ì»¬ëŸ¼
                candidate_start = 0
                if col_map.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜") is not None:
                    candidate_start = col_map["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] + 1
                elif col_map.get("ì¸µêµ¬ë¶„") is not None:
                    candidate_start = col_map["ì¸µêµ¬ë¶„"] + 1

                max_price_int = 0
                price_val = ""

                for c_idx in range(candidate_start, len(row)):
                    cell = get_val_idx(row, c_idx)
                    digits = re.sub(r"[^0-9]", "", cell)
                    if not digits:
                        continue
                    val_int = int(digits)
                    # ë„ˆë¬´ ì‘ì€ ê°’(ì˜ˆ: 100,000 ì´í•˜ëŠ” ì˜µì…˜/ìˆ˜ìˆ˜ë£Œì¼ ê°€ëŠ¥ì„±ì´ í¼)
                    if val_int <= 100000:
                        continue
                    if val_int > max_price_int:
                        max_price_int = val_int
                        price_val = cell

                # ê³µê¸‰ê¸ˆì•¡ ì†Œê³„ê°€ ì—†ìœ¼ë©´ ì´ í–‰ì€ ìŠ¤í‚µ
                if max_price_int == 0:
                    continue

                # ë™/í˜¸, ì¸µ, ì„¸ëŒ€ìˆ˜ ì…‹ ë‹¤ ë¹„ì–´ ìˆìœ¼ë©´ ë²„ë¦¼
                if not (current_dongho or floor_val or haedang_val):
                    continue
                # íƒ€ì… ì •ë³´ë„ ì—†ìœ¼ë©´ ë²„ë¦¼
                if not (current_type or current_abbr):
                    continue

                rec: Dict[str, str] = {
                    "ì£¼íƒí˜•": current_type,
                    "ì•½ì‹í‘œê¸°": current_abbr,
                    "ë™/í˜¸ë³„": current_dongho,
                    "ì¸µêµ¬ë¶„": floor_val,
                    "í•´ë‹¹ì„¸ëŒ€ìˆ˜": haedang_val,
                    "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„": price_val,
                }

                results.append(rec)

    # --------- (ì •ë¦¬ ë‹¨ê³„) ê°™ì€ ë™/í˜¸/ì¸µ ì¡°í•© ì¤‘ ê³µê¸‰ê¸ˆì•¡ì´ ê°€ì¥ í° í–‰ë§Œ ë‚¨ê¸°ê¸° ---------
    dedup: Dict[Tuple[str, str, str, str], Dict[str, str]] = {}

    for rec in results:
        key = (
            rec.get("ì£¼íƒí˜•", ""),
            rec.get("ì•½ì‹í‘œê¸°", ""),
            rec.get("ë™/í˜¸ë³„", ""),
            rec.get("ì¸µêµ¬ë¶„", ""),
        )
        price_digits = re.sub(r"[^0-9]", "", rec.get("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„", "") or "0")
        price_int = int(price_digits) if price_digits else 0

        if key not in dedup:
            dedup[key] = rec
        else:
            old_price_digits = re.sub(
                r"[^0-9]", "", dedup[key].get("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„", "") or "0"
            )
            old_price_int = int(old_price_digits) if old_price_digits else 0
            if price_int > old_price_int:
                dedup[key] = rec

    final_rows = list(dedup.values())
    return final_rows

def extract_price_table_with_layout(uploaded) -> List[Dict[str, str]]:
    """
    PyMuPDF(ë ˆì´ì•„ì›ƒ ê¸°ë°˜)ìœ¼ë¡œ ê³µê¸‰ê¸ˆì•¡í‘œ(ë™Â·í˜¸Â·ì¸µë³„)ë¥¼ ì¶”ì¶œí•œë‹¤.
    - ì£¼íƒí˜•
    - ì•½ì‹í‘œê¸°
    - ë™/í˜¸ë³„
    - ì¸µêµ¬ë¶„
    - í•´ë‹¹ì„¸ëŒ€ìˆ˜
    - ê³µê¸‰ê¸ˆì•¡ ì†Œê³„
    """

    # 1) ì—…ë¡œë“œëœ PDFë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    uploaded.seek(0)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(uploaded.read())
        tmp_path = tmp.name

    doc = fitz.open(tmp_path)

    results: List[Dict[str, str]] = []

    # ì»¬ëŸ¼ë³„ xì„¼í„° ì¢Œí‘œ (í—¤ë”ì—ì„œ í•œ ë²ˆ ì¡ìœ¼ë©´ ì´í›„ í˜ì´ì§€ì—ì„œë„ ì¬ì‚¬ìš©)
    col_centers: Dict[str, float] = {}
    header_y: float | None = None

    # forward-fillìš© ìƒíƒœ
    current_type = ""
    current_abbr = ""
    current_dongho = ""

    # yê°’ ê¸°ì¤€ìœ¼ë¡œ í–‰ ë¬¶ëŠ” í—¬í¼
    def group_by_y(words, tol=2.0):
        """[(x,y,text), ...] -> [(y_center, [words...]), ...]"""
        words_sorted = sorted(words, key=lambda w: w["y"])
        rows = []
        cur = []
        last_y = None
        for w in words_sorted:
            if last_y is None or abs(w["y"] - last_y) <= tol:
                cur.append(w)
                last_y = w["y"] if last_y is None else (last_y + w["y"]) / 2
            else:
                rows.append((last_y, cur))
                cur = [w]
                last_y = w["y"]
        if cur:
            rows.append((last_y, cur))
        return rows

    def is_floor_like(s: str) -> bool:
        if not s:
            return False
        t = s.replace(" ", "")
        return "ì¸µ" in t and not ("ë™" in t or "í˜¸" in t)

    for page in doc:
        page_text = page.get_text()
        # ê³µê¸‰ê¸ˆì•¡í‘œê°€ ì—†ëŠ” í˜ì´ì§€ëŠ” ìŠ¤í‚µ
        if "ê³µê¸‰ê¸ˆì•¡" not in page_text or "ì†Œê³„" not in page_text:
            continue

        # PyMuPDF words: [x0, y0, x1, y1, text, block_no, line_no, word_no]
        raw_words = page.get_text("words") or []
        words = [
            {
                "x": (w[0] + w[2]) / 2.0,
                "y": (w[1] + w[3]) / 2.0,
                "text": str(w[4]).strip(),
            }
            for w in raw_words
            if str(w[4]).strip()
        ]

        if not words:
            continue

        rows = group_by_y(words, tol=2.0)

        # ---- 1) í—¤ë” í–‰ ì°¾ê¸° (ìˆìœ¼ë©´ ì»¬ëŸ¼ ìœ„ì¹˜ ê°±ì‹ ) ----
        header_found_here = False
        for y_center, row_words in rows:
            row_text = "".join(w["text"] for w in row_words)
            if "ì£¼íƒí˜•" in row_text and ("ì•½ì‹í‘œê¸°" in row_text or "ì•½ì‹" in row_text):
                header_found_here = True
                header_y = y_center

                # ìƒˆë¡œ col_centers ì„¤ì •
                new_centers: Dict[str, float] = {}
                for w in row_words:
                    t = w["text"].replace(" ", "")
                    x = w["x"]
                    if "ì£¼íƒí˜•" in t:
                        new_centers["ì£¼íƒí˜•"] = x
                    elif "ì•½ì‹" in t:
                        new_centers["ì•½ì‹í‘œê¸°"] = x
                    elif "ë™" in t and "í˜¸" in t:
                        new_centers["ë™/í˜¸ë³„"] = x
                    elif "ì¸µêµ¬ë¶„" in t or ("ì¸µ" in t and "êµ¬ë¶„" in t):
                        new_centers["ì¸µêµ¬ë¶„"] = x
                    elif "í•´ë‹¹ì„¸ëŒ€" in t:
                        new_centers["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] = x
                    elif "ê³µê¸‰ê¸ˆì•¡" in t and "ì†Œê³„" in t:
                        new_centers["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] = x

                # ê³µê¸‰ê¸ˆì•¡ ì†Œê³„ ëª» ì°¾ìœ¼ë©´ ê°€ì¥ ì˜¤ë¥¸ìª½ì— ìˆëŠ” í—¤ë”ë¥¼ ê°€ê²©ìœ¼ë¡œ ì‚¬ìš©
                if "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„" not in new_centers:
                    right_word = max(row_words, key=lambda w: w["x"])
                    new_centers["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] = right_word["x"]

                col_centers = new_centers
                break

        # ì´ í˜ì´ì§€ì— í—¤ë”ê°€ ì—†ê³ , ì´ì „ì—ë„ col_centersë¥¼ ëª» ì¡ì•˜ìœ¼ë©´ ìŠ¤í‚µ
        if not col_centers:
            continue

        # ---- 2) ì‹¤ì œ ë°ì´í„° í–‰ ì²˜ë¦¬ ----
        # header_y ê¸°ì¤€ìœ¼ë¡œ ê·¸ ì•„ë˜ë§Œ ë°ì´í„° í–‰ìœ¼ë¡œ ë´„
        data_rows = []
        for y_center, row_words in rows:
            if header_y is not None and y_center <= header_y + 1:
                continue
            data_rows.append((y_center, row_words))

        for y_center, row_words in data_rows:
            row_text = "".join(w["text"] for w in row_words)

            # ì˜µì…˜í‘œ/í•©ê³„/ì „íƒ€ì… ë“±ì€ ìŠ¤í‚µ
            if any(k in row_text for k in ["í•©ê³„", "ì „íƒ€ì…", "ë¶€ë¶„", "ì˜µì…˜", "ì„ íƒí’ˆëª©", "ì„ íƒì‚¬ì–‘"]):
                continue

            # ì´ í–‰ì—ì„œ íŠ¹ì • ì»¬ëŸ¼(xì„¼í„°)ì— ê°€ì¥ ê°€ê¹Œìš´ ë‹¨ì–´ ì°¾ì•„ì£¼ëŠ” í—¬í¼
            def pick_nearest(col_name: str) -> str:
                if col_name not in col_centers:
                    return ""
                cx = col_centers[col_name]
                best = None
                best_diff = None
                for w in row_words:
                    diff = abs(w["x"] - cx)
                    # ë„ˆë¬´ ë–¨ì–´ì§„ ê±´ ê°™ì€ ì—´ì´ ì•„ë‹ˆë¼ê³  íŒë‹¨ (50pt ì •ë„ ê¸°ì¤€)
                    if diff > 50:
                        continue
                    if best is None or diff < best_diff:
                        best = w
                        best_diff = diff
                return best["text"] if best is not None else ""

            v_type = pick_nearest("ì£¼íƒí˜•")
            v_abbr = pick_nearest("ì•½ì‹í‘œê¸°")
            v_dongho = pick_nearest("ë™/í˜¸ë³„")
            v_floor = pick_nearest("ì¸µêµ¬ë¶„")
            v_haedang = pick_nearest("í•´ë‹¹ì„¸ëŒ€ìˆ˜")
            v_price = pick_nearest("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„")

            # forward-fill
            if v_type:
                current_type = v_type
            if v_abbr:
                current_abbr = v_abbr
            if v_dongho:
                current_dongho = v_dongho

            # ë™/í˜¸ ëŒ€ì‹  ì¸µì´ ë“¤ì–´ì™”ìœ¼ë©´ ë³´ì •
            if is_floor_like(v_dongho) and not is_floor_like(v_floor):
                v_floor = v_dongho
                v_dongho = current_dongho

            # ì¸µí‘œì‹œì— 'ì¸µ' ê¸€ì ì—†ìœ¼ë©´ ë¶™ì—¬ì£¼ê¸°
            if v_floor:
                fv = v_floor.replace(" ", "")
                if "ì¸µ" not in fv and re.search(r"\d", fv):
                    v_floor = fv + "ì¸µ"

            # ì„¸ëŒ€ìˆ˜: 4ìë¦¬(1000ì„¸ëŒ€) ì´ìƒì´ë©´ ê¸ˆì•¡ìœ¼ë¡œ ë³´ê³  ì œê±°
            if v_haedang:
                digits = re.sub(r"[^0-9]", "", v_haedang)
                if digits and len(digits) > 3:
                    v_haedang = ""

            # ê³µê¸‰ê¸ˆì•¡: ë„ˆë¬´ ì‘ì€ ê¸ˆì•¡(<= 1,000,000)ì€ ë©´ì /ìˆ˜ìˆ˜ë£Œë¡œ ë³´ê³  ë¬´ì‹œ
            if v_price:
                p_digits = re.sub(r"[^0-9]", "", v_price)
                if not p_digits or int(p_digits) <= 1000000:
                    v_price = ""

            # ìµœì†Œí•œì˜ ì •ë³´ ì²´í¬
            if not (current_type or current_abbr):
                continue
            if not (current_dongho or v_floor or v_haedang):
                continue
            if not v_price:
                # ê°€ê²©ì´ ë¹„ì—ˆìœ¼ë©´ ì´ í–‰ì€ ë²„ë¦°ë‹¤ (í•„ìš”í•˜ë©´ ë‚˜ì¤‘ì— ë³´ì™„)
                continue

            rec: Dict[str, str] = {
                "ì£¼íƒí˜•": current_type,
                "ì•½ì‹í‘œê¸°": current_abbr,
                "ë™/í˜¸ë³„": current_dongho,
                "ì¸µêµ¬ë¶„": v_floor,
                "í•´ë‹¹ì„¸ëŒ€ìˆ˜": v_haedang,
                "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„": v_price,
            }
            results.append(rec)

    return results


# ============================
# Streamlit UI
# ============================
st.set_page_config(page_title="ì…ì£¼ìëª¨ì§‘ê³µê³  ë¶„ì„ê¸°", layout="wide")

st.sidebar.title("ğŸ“‚ PDF ì—…ë¡œë“œ")
uploaded = st.sidebar.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])

st.title("ğŸ¢ ì…ì£¼ìëª¨ì§‘ê³µê³  ë¶„ì„ê¸° (ìë™ ë¶„ì„)")

if uploaded:
    uploaded.seek(0)
    with pdfplumber.open(uploaded) as pdf:
        schedule = extract_schedule_from_table(pdf)
        table_company = extract_company_from_table(pdf, text)
        supply_rows = extract_supply_target_from_tables(pdf)

    # ğŸ”½ ê³µê¸‰ê¸ˆì•¡í‘œ: PyMuPDF ë ˆì´ì•„ì›ƒ ì—”ì§„ ìš°ì„ , ì•ˆ ë˜ë©´ ê¸°ì¡´ pdfplumber ë²„ì „ ì‚¬ìš©
    try:
        price_rows = extract_price_table_with_layout(uploaded)
        if not price_rows:
            uploaded.seek(0)
            with pdfplumber.open(uploaded) as pdf2:
                price_rows = extract_price_table_from_tables(pdf2)
    except Exception:
        uploaded.seek(0)
        with pdfplumber.open(uploaded) as pdf2:
            price_rows = extract_price_table_from_tables(pdf2)


    core = extract_core_info(text)
    loan_cond = extract_loan_condition(text)
    move_in = extract_move_in_date(text)

    st.subheader("ğŸ§  ìë™ ë¶„ì„ ê²°ê³¼")

    st.markdown(f"**ğŸ¢ ë‹¨ì§€ëª…:** {parse_complex_name(text) or 'ì •ë³´ ì—†ìŒ'}")
    st.markdown(f"**ğŸ“ ê³µê¸‰ ìœ„ì¹˜:** {parse_location(text) or 'ì •ë³´ ì—†ìŒ'}")

    st.subheader("ğŸ“Œ í•µì‹¬ ì •ë³´ ìš”ì•½")
    st.write(f"- **ê³µê¸‰ê·œëª¨:** {core.get('ê³µê¸‰ê·œëª¨') or 'ì •ë³´ ì—†ìŒ'}")
    st.write(f"- **ì…ì£¼ì˜ˆì •ì¼:** {move_in or 'ì •ë³´ ì—†ìŒ'}")

    final_siheng = table_company.get("ì‹œí–‰ì‚¬") or core.get("ì‹œí–‰ì‚¬")
    st.write(f"- **ì‹œí–‰ì‚¬:** {final_siheng or 'ì •ë³´ ì—†ìŒ'}")

    final_sigong = table_company.get("ì‹œê³µì‚¬") or core.get("ì‹œê³µì‚¬")
    st.write(f"- **ì‹œê³µì‚¬:** {final_sigong or 'ì •ë³´ ì—†ìŒ'}")

    final_agency = table_company.get("ë¶„ì–‘ëŒ€í–‰ì‚¬")
    if final_agency:
        st.write(f"- **ë¶„ì–‘ëŒ€í–‰ì‚¬:** {final_agency}")

    st.write(f"- **ì¤‘ë„ê¸ˆ ëŒ€ì¶œ ì¡°ê±´:** {loan_cond or 'ì •ë³´ ì—†ìŒ'}")

    st.subheader("ğŸ“… ì²­ì•½ ì¼ì • ìë™ ë¶„ë¥˜")

    order = [
        "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ë‹¹ì²¨ìë°œí‘œì¼",
        "ì„œë¥˜ì ‘ìˆ˜",
        "ê³„ì•½ì²´ê²°",
    ]

    rows = []
    for key in order:
        val = schedule.get(key)
        rows.append({"í•­ëª©": key, "ì¼ì •": val or "ì •ë³´ ì—†ìŒ"})
        st.write(f"- **{key}**: {val or 'ì •ë³´ ì—†ìŒ'}")

    df_schedule = pd.DataFrame(rows)
    st.table(df_schedule)

    st.subheader("ğŸ  ê³µê¸‰ëŒ€ìƒ (íƒ€ì…ë³„ ìš”ì•½)")
    if supply_rows:
        df_supply = pd.DataFrame(supply_rows)
        st.table(df_supply)
    else:
        st.info("ê³µê¸‰ëŒ€ìƒ í‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.subheader("ğŸ’° ê³µê¸‰ê¸ˆì•¡í‘œ (ë™Â·í˜¸Â·ì¸µë³„)")
    if price_rows:
        df_price = pd.DataFrame(price_rows)
        st.table(df_price)
    else:
        st.info("ê³µê¸‰ê¸ˆì•¡í‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    complex_name = parse_complex_name(text) or ""
    location = parse_location(text) or ""

    # ì—‘ì…€ìš©ìœ¼ë¡œë„ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì •ë¦¬ (í˜¹ì‹œë¼ë„ ìƒê¸¸ ê²½ìš° ëŒ€ë¹„)
    clean_price_rows = []
    for row in price_rows:
        clean = {
            "ì£¼íƒí˜•": row.get("ì£¼íƒí˜•", ""),
            "ì•½ì‹í‘œê¸°": row.get("ì•½ì‹í‘œê¸°", ""),
            "ë™/í˜¸ë³„": row.get("ë™/í˜¸ë³„", ""),
            "ì¸µêµ¬ë¶„": row.get("ì¸µêµ¬ë¶„", ""),
            "í•´ë‹¹ì„¸ëŒ€ìˆ˜": row.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜", ""),
            "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„": row.get("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„", ""),
        }
        clean_price_rows.append(clean)

    excel_bytes = make_excel_file(
        complex_name=complex_name,
        location=location,
        core=core,
        move_in=move_in,
        final_siheng=final_siheng,
        final_sigong=final_sigong,
        final_agency=final_agency,
        loan_cond=loan_cond,
        schedule_rows=rows,
        supply_rows=supply_rows,
        price_rows=clean_price_rows,
    )

    st.download_button(
        label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=excel_bytes,
        file_name=f"{complex_name or 'ë¶„ì–‘ë‹¨ì§€'}_ëª¨ì§‘ê³µê³ _ìë™ë¶„ì„.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

else:
    st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
