import streamlit as st
import pdfplumber
import re
from io import BytesIO
from datetime import datetime
import pandas as pd
from typing import Dict, List, Tuple
from collections import defaultdict

# ============================
#  ê³µí†µ ìœ í‹¸
# ============================
def parse_ymd(date_str: str):
    try:
        return datetime.strptime(date_str, "%Y.%m.%d").date()
    except:
        return None


# ============================
#  ë‹¨ì§€ëª… ì¶”ì¶œ
# ============================
def parse_complex_name(text: str):
    raw = None
    for line in text.splitlines():
        line = line.strip()
        if "ì…ì£¼ìëª¨ì§‘ê³µê³ " in line:
            raw = line.replace("ì…ì£¼ìëª¨ì§‘ê³µê³ ", "").strip()
            break

    if not raw:
        return None

    name = re.sub(r"\s+", " ", raw)
    name = name.strip(" ,Â·-")
    return name or None


# ============================
#  ê³µê¸‰ìœ„ì¹˜ ì¶”ì¶œ
# ============================
def parse_location(text: str):
    keywords = ["ê³µê¸‰ìœ„ì¹˜", "ì‚¬ì—…ìœ„ì¹˜", "ê±´ì„¤ìœ„ì¹˜", "ëŒ€ì§€ìœ„ì¹˜"]
    for line in text.splitlines():
        for key in keywords:
            if key in line:
                cleaned = line.replace(key, "")
                cleaned = cleaned.replace(":", "")
                cleaned = cleaned.replace("â– ", "")
                cleaned = cleaned.replace("ìœ„ì¹˜", "").strip()
                cleaned = re.sub(r"\s+", " ", cleaned)
                return cleaned
    return None


# ============================
#  ë¶ˆí•„ìš” ë¬¸ë‹¨(ìœ ì˜ì‚¬í•­Â·ë¬´ì£¼íƒê¸°ê°„ ë“±) ì œê±°
# ============================
def filter_irrelevant_sections(text: str) -> str:
    """
    ëª¨ì§‘ê³µê³  ì¤‘ 4~7, 11í•­ëª©ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ”
    'ìœ ì˜ì‚¬í•­/ë¬´ì£¼íƒê¸°ê°„ ì ìš©ê¸°ì¤€/ê¸°íƒ€ ì•ˆë‚´' ë“±ì€
    í•µì‹¬ì •ë³´ ì¶”ì¶œì— ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ë¶„ì„ í…ìŠ¤íŠ¸ì—ì„œ ì œê±°í•œë‹¤.
    """
    remove_keywords = [
        "ë¬´ì£¼íƒê¸°ê°„ ì ìš©ê¸°ì¤€",
        "ë¬´ì£¼íƒ ê¸°ê°„ ì ìš©ê¸°ì¤€",
        "ë¬´ì£¼íƒê¸°ê°„ ì‚°ì •ê¸°ì¤€",
        "ì²­ì•½ ì‹œ ìœ ì˜ì‚¬í•­",
        "ì²­ì•½ì‹œ ìœ ì˜ì‚¬í•­",
        "ìœ ì˜ì‚¬í•­",
        "ê¸°íƒ€ ì‚¬í•­",
        "ê¸°íƒ€ì‚¬í•­",
        "ê³µê¸‰(ë¶„ì–‘)ê³„ì•½ì— ê´€í•œ ìœ ì˜ì‚¬í•­",
        "ê³„ì•½ì²´ê²°ì‹œ ìœ ì˜ì‚¬í•­",
    ]

    filtered_lines = []
    for line in text.splitlines():
        s = line.strip()
        if any(k in s for k in remove_keywords):
            continue
        filtered_lines.append(line)

    return "\n".join(filtered_lines)


# ============================
#  íšŒì‚¬ëª… ì •ê·œí™” + íŒë³„ ìœ í‹¸
# ============================
def normalize_company_name(name: str) -> str:
    if not name:
        return ""
    name = str(name)

    name = name.replace("\n", " ")
    name = re.sub(r"\s+", " ", name).strip()

    name = name.lstrip("â€»*â€¢-Â·[]() ")

    name = name.replace(" (ì£¼)", "(ì£¼)").replace("(ì£¼) ", "(ì£¼)")
    name = name.replace(" ãˆœ", "ãˆœ").replace("ãˆœ ", "ãˆœ")

    if name.endswith("(ì£¼"):
        name = name + ")"
    if re.search(r"\(ì£¼$", name):
        name = name + ")"

    if "â€»" in name:
        name = name.split("â€»", 1)[0].strip()

    return name.strip()


COMPANY_HINT_KEYWORDS = [
    "ì¡°í•©", "ê±´ì„¤", "ì£¼ì‹íšŒì‚¬", "ãˆœ", "(ì£¼)", "ê°œë°œ",
    "ë””ì•¤ì”¨", "ë””ì—”ì”¨", "ì‚°ì—…", "ì—”ì§€ë‹ˆì–´ë§",
    "í™€ë”©ìŠ¤", "íˆ¬ì", "ê³µì‚¬", "ê¸°ì—…", "ì£¼íƒë„ì‹œ",
]


def looks_like_company(name: str) -> bool:
    if not name:
        return False
    name = name.strip()
    if len(name) > 30:
        return False

    bad_endings = ["ê¸°ì¤€", "ì ìš©ê¸°ì¤€", "ì ìš© ê¸°ì¤€", "ì‚°ì •ê¸°ì¤€"]
    if any(name.endswith(be) for be in bad_endings):
        return False

    strong_keywords = ["ì¡°í•©", "ê±´ì„¤", "ì£¼ì‹íšŒì‚¬", "ãˆœ", "(ì£¼)", "ê°œë°œ", "ê³µì‚¬", "ê¸°ì—…"]
    if "ê¸°ê°„" in name and not any(k in name for k in strong_keywords):
        return False

    if any(word in name for word in ["ê´‘ì—­ì‹œ", "íŠ¹ë³„ì‹œ", "ì‹œ ", "êµ° ", "êµ¬ ", "ë™ ", "ë¡œ ", "ê¸¸ "]):
        if not any(k in name for k in COMPANY_HINT_KEYWORDS):
            return False

    return any(k in name for k in COMPANY_HINT_KEYWORDS)


# ============================
#  í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹œí–‰/ì‹œê³µ/ë¶„ì–‘ ì¶”ì¶œ
# ============================
def extract_companies_from_text(text: str) -> Dict[str, List[str]]:
    result = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }

    norm = text.replace("ï¼š", ":")
    norm = re.sub(r"\s+", " ", norm)

    patterns = {
        "ì‹œí–‰ì‚¬": [
            r"(?:ì‚¬ì—…ì£¼ì²´|ì‹œí–‰ì|ì‹œí–‰ì‚¬)\s*[:]\s*([^\n:]+)",
        ],
        "ì‹œê³µì‚¬": [
            r"(?:ì‹œê³µì|ì‹œê³µì‚¬|ì‹œê³µ)\s*[:]\s*([^\n:]+)",
        ],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [
            r"(?:ë¶„ì–‘ëŒ€í–‰ì‚¬|ë¶„ì–‘ëŒ€í–‰|ë¶„ì–‘ëŒ€ë¦¬ì )\s*[:]\s*([^\n:]+)",
        ],
    }

    for role, pats in patterns.items():
        for pat in pats:
            for m in re.finditer(pat, norm):
                name = normalize_company_name(m.group(1))
                if looks_like_company(name) and name not in result[role]:
                    result[role].append(name)

    simple_patterns = {
        "ì‹œí–‰ì‚¬": [
            r"(?:ì‚¬ì—…ì£¼ì²´|ì‹œí–‰ì|ì‹œí–‰ì‚¬)\s+([^\n:]+)",
        ],
        "ì‹œê³µì‚¬": [
            r"(?:ì‹œê³µì|ì‹œê³µì‚¬|ì‹œê³µ)\s+([^\n:]+)",
        ],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [
            r"(?:ë¶„ì–‘ëŒ€í–‰ì‚¬|ë¶„ì–‘ëŒ€í–‰|ë¶„ì–‘ëŒ€ë¦¬ì )\s+([^\n:]+)",
        ],
    }

    for role, pats in simple_patterns.items():
        for pat in pats:
            for m in re.finditer(pat, norm):
                name = normalize_company_name(m.group(1))
                if looks_like_company(name) and name not in result[role]:
                    result[role].append(name)

    combo_pattern = r"(ì‹œí–‰|ì‹œê³µ|ë¶„ì–‘ëŒ€í–‰)\s*[: ]\s*([^/]+)"
    for m in re.finditer(combo_pattern, norm):
        key = m.group(1)
        name = normalize_company_name(m.group(2))
        if "ì‹œí–‰" in key:
            role = "ì‹œí–‰ì‚¬"
        elif "ì‹œê³µ" in key:
            role = "ì‹œê³µì‚¬"
        else:
            role = "ë¶„ì–‘ëŒ€í–‰ì‚¬"
        if looks_like_company(name) and name not in result[role]:
            result[role].append(name)

    return result


# ============================
#  í•µì‹¬ ì •ë³´(ê³µê¸‰ê·œëª¨ + í…ìŠ¤íŠ¸ ë°±ì—…ìš© ì‹œí–‰/ì‹œê³µ) ì¶”ì¶œ
# ============================
def extract_core_info(text: str):
    info = {
        "ê³µê¸‰ê·œëª¨": None,
        "ì‹œí–‰ì‚¬": None,
        "ì‹œê³µì‚¬": None,
    }

    for line in text.splitlines():
        s = line.strip()
        if not s:
            continue

        if not info["ê³µê¸‰ê·œëª¨"] and ("ê³µê¸‰ê·œëª¨" in s or "ì´ ê³µê¸‰ì„¸ëŒ€ìˆ˜" in s):
            cleaned = s
            cleaned = cleaned.replace("â– ", "")
            cleaned = cleaned.replace("â—", "")
            cleaned = cleaned.replace("ê³µê¸‰ê·œëª¨", "")
            cleaned = cleaned.replace("ì´ ê³µê¸‰ì„¸ëŒ€ìˆ˜", "")
            cleaned = cleaned.replace(":", "")
            cleaned = cleaned.strip()
            info["ê³µê¸‰ê·œëª¨"] = cleaned
            continue

        if not info["ì‹œí–‰ì‚¬"] and ("ì‹œí–‰ì" in s or "ì‹œí–‰ì‚¬" in s):
            cleaned = s
            cleaned = cleaned.replace("â– ", "").replace("â—", "")
            cleaned = cleaned.replace("ì‹œí–‰ì", "").replace("ì‹œí–‰ì‚¬", "")
            cleaned = cleaned.replace(":", "")
            cleaned = cleaned.strip()

            cleaned = normalize_company_name(cleaned)
            if looks_like_company(cleaned):
                info["ì‹œí–‰ì‚¬"] = cleaned
            continue

        if not info["ì‹œê³µì‚¬"] and ("ì‹œê³µì" in s or "ì‹œê³µì‚¬" in s):
            cleaned = s
            cleaned = cleaned.replace("â– ", "").replace("â—", "")
            cleaned = cleaned.replace("ì‹œê³µì", "").replace("ì‹œê³µì‚¬", "")
            cleaned = cleaned.replace(":", "")
            cleaned = cleaned.strip()

            cleaned = normalize_company_name(cleaned)
            if looks_like_company(cleaned):
                info["ì‹œê³µì‚¬"] = cleaned
            continue

    return info


# ============================
#  ì…ì£¼ ì˜ˆì •ì¼ ì¶”ì¶œ
# ============================
def extract_move_in_date(text: str) -> str | None:
    candidate_lines: List[str] = []

    for line in text.splitlines():
        s = line.strip()
        if not s:
            continue

        no_space = s.replace(" ", "")

        if any(k in no_space for k in ["ì…ì£¼ì‹œê¸°", "ì…ì£¼ì‹œê¸°", "ì…ì£¼ì˜ˆì •", "ì…ì£¼ì˜ˆì •ì¼"]):
            candidate_lines.append(s)

    for s in candidate_lines:
        m = re.search(r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”", s)
        if m:
            year = int(m.group(1))
            month = int(m.group(2))
            return f"{year}ë…„ {month}ì›”"

        m2 = re.search(r"(\d{4})\.(\d{1,2})", s)
        if m2:
            year = int(m2.group(1))
            month = int(m2.group(2))
            return f"{year}ë…„ {month}ì›”"

    if candidate_lines:
        first = candidate_lines[0]
        return first[:40] + "..." if len(first) > 40 else first

    return None


# ============================
#  í‘œ ê¸°ë°˜ íšŒì‚¬ì •ë³´ ì¶”ì¶œ ìœ í‹¸
# ============================
ROLE_KEYWORDS = {
    "ì‹œí–‰ì‚¬": ["ì‚¬ì—…ì£¼ì²´", "ì‹œí–‰ì", "ì‹œí–‰ì‚¬", "ì‚¬ì—…ì‹œí–‰ì"],
    "ì‹œê³µì‚¬": ["ì‹œê³µì‚¬", "ì‹œê³µì", "ì‹œê³µ"],
    "ë¶„ì–‘ëŒ€í–‰ì‚¬": ["ë¶„ì–‘ëŒ€í–‰ì‚¬", "ë¶„ì–‘ëŒ€í–‰", "ë¶„ì–‘ëŒ€ë¦¬ì ", "ìœ„íƒì‚¬"],
}


def detect_role_from_header(text: str) -> List[str]:
    roles = []
    t = text.replace(" ", "")
    for role, keywords in ROLE_KEYWORDS.items():
        if any(k in t for k in keywords):
            roles.append(role)
    return roles


def extract_from_vertical_label_table(
    df: pd.DataFrame,
    page_idx: int,
) -> Dict[str, List[Tuple[str, int]]]:
    res = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }
    if df.empty:
        return res

    df = df.fillna("")
    label_col = df.iloc[:, 0].astype(str)

    for i, label in enumerate(label_col):
        roles = detect_role_from_header(label)
        if not roles:
            continue
        row = df.iloc[i, 1:]
        candidates = [normalize_company_name(v) for v in row if str(v).strip()]
        for role in roles:
            for c in candidates:
                if looks_like_company(c):
                    res[role].append((c, page_idx))

    return res


def extract_from_horizontal_header_table(
    df: pd.DataFrame,
    page_idx: int,
) -> Dict[str, List[Tuple[str, int]]]:
    res = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }
    if df.empty or len(df) < 2:
        return res

    df = df.fillna("")
    header = df.iloc[0].astype(str).tolist()
    body = df[1:]

    for col_idx, h in enumerate(header):
        roles = detect_role_from_header(h)
        if not roles:
            continue
        col_values = body.iloc[:, col_idx].astype(str)
        candidates = [
            normalize_company_name(v)
            for v in col_values
            if str(v).strip()
        ]
        for role in roles:
            for c in candidates:
                if looks_like_company(c):
                    res[role].append((c, page_idx))

    return res


def extract_company_candidates_from_pdf(pdf) -> Tuple[Dict[str, List[Tuple[str, int]]], int]:
    result = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }

    last_page_idx = len(pdf.pages) - 1 if pdf.pages else 0

    for page_idx, page in enumerate(pdf.pages):
        tables = page.extract_tables() or []
        for table in tables:
            if not table:
                continue
            df = pd.DataFrame(table)
            if df.empty:
                continue

            vertical = extract_from_vertical_label_table(df, page_idx)
            horizontal = extract_from_horizontal_header_table(df, page_idx)

            for role in result.keys():
                result[role].extend(vertical.get(role, []))
                result[role].extend(horizontal.get(role, []))

    return result, last_page_idx


def choose_final_company(
    text_candidates: Dict[str, List[str]],
    table_candidates: Dict[str, List[Tuple[str, int]]],
    last_page_idx: int = None,
) -> Dict[str, str]:
    scores: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))

    for role, vals in table_candidates.items():
        for name, page_idx in vals:
            if not name:
                continue
            base = 3
            bonus = 0
            if last_page_idx is not None and page_idx == last_page_idx:
                bonus += 2
            scores[role][name] += base + bonus

    for role, names in text_candidates.items():
        for name in names:
            if not name:
                continue
            scores[role][name] += 2

    final = {
        "ì‹œí–‰ì‚¬": "",
        "ì‹œê³µì‚¬": "",
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": "",
    }

    for role, name_scores in scores.items():
        if not name_scores:
            continue
        sorted_candidates = sorted(
            name_scores.items(),
            key=lambda x: (x[1], len(x[0])),
            reverse=True,
        )
        final[role] = sorted_candidates[0][0]

    return final


# ============================
#  í…ìŠ¤íŠ¸ + í‘œ ê¸°ë°˜ í†µí•© ì¶”ì¶œ
# ============================
def extract_company_from_table(pdf, text: str) -> Dict[str, str]:
    text_candidates = extract_companies_from_text(text)
    table_candidates, last_page_idx = extract_company_candidates_from_pdf(pdf)
    final = choose_final_company(text_candidates, table_candidates, last_page_idx)
    return final


# ============================
#  ì¤‘ë„ê¸ˆ ëŒ€ì¶œ ì¡°ê±´ ì¶”ì¶œ
# ============================
def extract_loan_condition(text: str):
    condition = None
    related_lines = []

    for line in text.splitlines():
        s = line.strip()
        if "ì¤‘ë„ê¸ˆ" in s and "ëŒ€ì¶œ" in s:
            related_lines.append(s)
        elif "ì¤‘ë„ê¸ˆ" in s and "ì´ì" in s:
            related_lines.append(s)

    joined = " ".join(related_lines)

    if "ì´ìí›„ë¶ˆì œ" in joined or "ì´ì í›„ë¶ˆì œ" in joined:
        condition = "ì´ìí›„ë¶ˆì œ"
    elif "ë¬´ì´ì" in joined:
        condition = "ë¬´ì´ì"

    if not condition and joined:
        condition = joined

    return condition


# ============================
#  ì—‘ì…€ ë‹¤ìš´ë¡œë“œìš© íŒŒì¼ ìƒì„±
# ============================
def make_excel_file(
    complex_name: str,
    location: str,
    core: dict,
    move_in: str | None,
    final_siheng: str | None,
    final_sigong: str | None,
    final_agency: str | None,
    loan_cond: str | None,
    schedule_rows: list,
    supply_rows: list,
    price_rows: list,
) -> BytesIO:
    summary_rows = [
        {"í•­ëª©": "ë‹¨ì§€ëª…", "ê°’": complex_name},
        {"í•­ëª©": "ê³µê¸‰ìœ„ì¹˜", "ê°’": location},
        {"í•­ëª©": "ê³µê¸‰ê·œëª¨", "ê°’": core.get("ê³µê¸‰ê·œëª¨") or ""},
        {"í•­ëª©": "ì…ì£¼ì˜ˆì •ì¼", "ê°’": move_in or ""},
        {"í•­ëª©": "ì‹œí–‰ì‚¬", "ê°’": final_siheng or ""},
        {"í•­ëª©": "ì‹œê³µì‚¬", "ê°’": final_sigong or ""},
        {"í•­ëª©": "ë¶„ì–‘ëŒ€í–‰ì‚¬", "ê°’": final_agency or ""},
        {"í•­ëª©": "ì¤‘ë„ê¸ˆ ëŒ€ì¶œ ì¡°ê±´", "ê°’": loan_cond or ""},
    ]

    for row in schedule_rows:
        summary_rows.append({"í•­ëª©": row.get("í•­ëª©", ""), "ê°’": row.get("ì¼ì •", "")})

    df_summary = pd.DataFrame(summary_rows)
    df_supply = pd.DataFrame(supply_rows) if supply_rows else pd.DataFrame()
    df_price = pd.DataFrame(price_rows) if price_rows else pd.DataFrame()

    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        sheet_name = "ëª¨ì§‘ê³µê³ "

        df_summary.to_excel(writer, index=False, sheet_name=sheet_name, startrow=0)

        start_row = len(df_summary) + 2

        if not df_supply.empty:
            df_supply.to_excel(writer, index=False, sheet_name=sheet_name, startrow=start_row)
            start_row += len(df_supply) + 2

        if not df_price.empty:
            df_price.to_excel(writer, index=False, sheet_name=sheet_name, startrow=start_row)

    output.seek(0)
    return output


# ============================
#  í‘œì—ì„œ ì²­ì•½ ì¼ì • ì¶”ì¶œ
# ============================
def extract_schedule_from_table(pdf):
    schedule = {
        "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼": None,
        "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼": None,
        "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼": None,
        "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼": None,
        "ë‹¹ì²¨ìë°œí‘œì¼": None,
        "ì„œë¥˜ì ‘ìˆ˜": None,
        "ê³„ì•½ì²´ê²°": None,
    }

    header_map = {
        "ì…ì£¼ìëª¨ì§‘ê³µê³ ": "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "ì…ì£¼ì ëª¨ì§‘ê³µê³ ": "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "íŠ¹ë³„ê³µê¸‰ì ‘ìˆ˜": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "íŠ¹ë³„ê³µê¸‰ ì‹ ì²­": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "1ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "1ìˆœìœ„": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "2ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "2ìˆœìœ„": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ë‹¹ì²¨ìë°œí‘œì¼": "ë‹¹ì²¨ìë°œí‘œì¼",
        "ë‹¹ì²¨ì ë°œí‘œ": "ë‹¹ì²¨ìë°œí‘œì¼",
        "ì„œë¥˜ì ‘ìˆ˜": "ì„œë¥˜ì ‘ìˆ˜",
        "ì •ë‹¹ê³„ì•½": "ê³„ì•½ì²´ê²°",
        "ê³„ì•½ì²´ê²°": "ê³„ì•½ì²´ê²°",
    }

    date_pattern = r"\d{4}\.\d{1,2}\.\d{1,2}"

    def update(label, new_val):
        old = schedule.get(label)
        if not old:
            schedule[label] = new_val
            return

        try:
            old_d = datetime.strptime(re.findall(date_pattern, old)[0], "%Y.%m.%d")
            new_d = datetime.strptime(re.findall(date_pattern, new_val)[0], "%Y.%m.%d")
            if new_d > old_d:
                schedule[label] = new_val
        except:
            pass

    for page in pdf.pages:
        tables = page.extract_tables() or []

        for table in tables:
            if not table:
                continue

            rows = table

            for r, row in enumerate(rows):
                for c, cell in enumerate(row):
                    if not cell:
                        continue
                    cell_t = cell.replace(" ", "")

                    for key, label in header_map.items():
                        if key.replace(" ", "") in cell_t:

                            for rr in range(r + 1, len(rows)):
                                if c >= len(rows[rr]):
                                    continue

                                raw = rows[rr][c] or ""
                                found = re.findall(date_pattern, raw)
                                if not found:
                                    continue

                                if label in ["ì„œë¥˜ì ‘ìˆ˜", "ê³„ì•½ì²´ê²°"] and len(found) >= 2:
                                    update(label, f"{found[0]} ~ {found[-1]}")
                                else:
                                    update(label, found[0])

                                break

    return schedule


# ============================
#  ê³µê¸‰ëŒ€ìƒ(íƒ€ì…ë³„) ì¶”ì¶œ
# ============================
def extract_supply_target_from_tables(pdf) -> List[Dict[str, str]]:
    results: List[Dict[str, str]] = []

    for page in pdf.pages:
        tables = page.extract_tables() or []
        for table in tables:
            if not table or len(table) < 3:
                continue

            df = pd.DataFrame(table).fillna("")
            header_idx = None

            for i, row in df.iterrows():
                row_txt = "".join(str(x) for x in row.tolist())
                if "ì£¼íƒí˜•" in row_txt and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹ í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt):
                    header_idx = i
                    break

            if header_idx is None:
                continue

            df2 = df.iloc[header_idx:].reset_index(drop=True)
            ncols = df2.shape[1]

            col_map: Dict[str, int] = {}
            for c in range(ncols):
                hdr = "".join(df2.iloc[0:4, c].astype(str).tolist())
                hdr = hdr.replace(" ", "").replace("\n", "")

                if "ì£¼íƒí˜•" in hdr:
                    col_map["ì£¼íƒí˜•"] = c
                elif "ì•½ì‹í‘œê¸°" in hdr or "ì•½ì‹í‘œì‹œ" in hdr or "ì•½ì‹" in hdr:
                    col_map["ì•½ì‹í‘œê¸°"] = c
                elif "ì£¼ê±°ì „ìš©ë©´ì " in hdr or ("ì „ìš©" in hdr and "ë©´ì " in hdr):
                    col_map["ì£¼ê±° ì „ìš©ë©´ì "] = c
                elif "ì†Œê³„" in hdr and "ì„¸ëŒ€" not in hdr:
                    col_map["ì£¼íƒê³µê¸‰ë©´ì  ì†Œê³„"] = c
                elif ("ì´ê³µê¸‰" in hdr and "ì„¸ëŒ€ìˆ˜" in hdr) or "ì´ê³µê¸‰ì„¸ëŒ€ìˆ˜" in hdr:
                    col_map["ì´ ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = c
                elif "ì¼ë°˜ê³µê¸‰" in hdr and "ì„¸ëŒ€ìˆ˜" in hdr:
                    col_map["ì¼ë°˜ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = c
                elif "ê¸°ê´€ì¶”ì²œ" in hdr:
                    col_map["ê¸°ê´€ì¶”ì²œ"] = c
                elif "ë‹¤ìë…€" in hdr:
                    col_map["ë‹¤ìë…€ê°€êµ¬"] = c
                elif "ì‹ í˜¼ë¶€ë¶€" in hdr:
                    col_map["ì‹ í˜¼ë¶€ë¶€"] = c
                elif "ë…¸ë¶€ëª¨" in hdr:
                    col_map["ë…¸ë¶€ëª¨ë¶€ì–‘"] = c
                elif "ìƒì• ìµœì´ˆ" in hdr:
                    col_map["ìƒì• ìµœì´ˆ"] = c

            if not col_map:
                continue

            for r in range(1, df2.shape[0]):
                row = df2.iloc[r]
                row_txt = "".join(str(x) for x in row.tolist())

                if "í•©ê³„" in row_txt:
                    continue

                def get_val(key: str) -> str:
                    idx = col_map.get(key)
                    if idx is None or idx >= len(row):
                        return ""
                    return str(row.iloc[idx]).strip()

                rec: Dict[str, str] = {}
                rec["ì£¼íƒí˜•"] = get_val("ì£¼íƒí˜•")
                rec["ì•½ì‹í‘œê¸°"] = get_val("ì•½ì‹í‘œê¸°")
                rec["ì£¼ê±° ì „ìš©ë©´ì "] = get_val("ì£¼ê±° ì „ìš©ë©´ì ")
                rec["ì£¼íƒê³µê¸‰ë©´ì  ì†Œê³„"] = get_val("ì£¼íƒê³µê¸‰ë©´ì  ì†Œê³„")
                rec["ì´ ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = get_val("ì´ ê³µê¸‰ ì„¸ëŒ€ìˆ˜")
                rec["ì¼ë°˜ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = get_val("ì¼ë°˜ê³µê¸‰ ì„¸ëŒ€ìˆ˜")

                special_total = 0
                for k in ["ê¸°ê´€ì¶”ì²œ", "ë‹¤ìë…€ê°€êµ¬", "ì‹ í˜¼ë¶€ë¶€", "ë…¸ë¶€ëª¨ë¶€ì–‘", "ìƒì• ìµœì´ˆ"]:
                    idx = col_map.get(k)
                    if idx is None or idx >= len(row):
                        continue
                    raw = str(row.iloc[idx])
                    num = re.sub(r"[^0-9]", "", raw)
                    if num:
                        special_total += int(num)

                rec["íŠ¹ë³„ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = str(special_total) if special_total > 0 else ""

                if not (rec.get("ì£¼íƒí˜•") or rec.get("ì•½ì‹í‘œê¸°")):
                    continue
                if ("ì£¼íƒí˜•" in rec.get("ì£¼íƒí˜•", "")) or ("ì•½ì‹" in rec.get("ì•½ì‹í‘œê¸°", "")):
                    continue

                results.append(rec)

            # íƒ€ì…í‘œëŠ” í•œ ë²ˆë§Œ ì°¾ìœ¼ë©´ ì¶©ë¶„í•˜ë‹ˆ, ì²« ë°œê²¬ í›„ ì¢…ë£Œ
            if results:
                return results

    return results


# ============================
#  ê³µê¸‰ê¸ˆì•¡í‘œ ì¶”ì¶œ (ë™Â·í˜¸Â·ì¸µë³„, ìˆ«ì ê¸°ë°˜ ê³µê¸‰ê¸ˆì•¡ ì—´ ìë™ íƒì§€)
# ============================
def extract_price_table_from_tables(pdf) -> List[Dict[str, str]]:
    """
    'ê³µê¸‰ê¸ˆì•¡í‘œ'ì—ì„œ
    - ì£¼íƒí˜•
    - ì•½ì‹í‘œê¸°
    - ë™/í˜¸ë³„
    - ì¸µêµ¬ë¶„
    - í•´ë‹¹ì„¸ëŒ€ìˆ˜
    - ê³µê¸‰ê¸ˆì•¡ ì†Œê³„
    ë¥¼ ì¶”ì¶œí•œë‹¤.

    í•µì‹¬ ì•„ì´ë””ì–´
    1) ì˜µì…˜/í™•ì¥ë¹„ í‘œëŠ” í…ìŠ¤íŠ¸ë¡œ ê±°ë¥¸ë‹¤.
    2) 6í˜ì´ì§€(í—¤ë” ìˆëŠ” í‘œ)ì—ì„œë§Œ í—¤ë”ë¥¼ ë¶„ì„í•´ì„œ col_mapì„ ë§Œë“ ë‹¤.
    3) ê³µê¸‰ê¸ˆì•¡ ì—´ì€ í—¤ë” í…ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼, ê° ì—´ì— ë“±ì¥í•˜ëŠ” ìˆ«ì ê¸¸ì´/ê°œìˆ˜ë¥¼ ë³´ê³ 
       "7ìë¦¬ ì´ìƒ ê¸ˆì•¡ì´ ë§ì´ ë‚˜ì˜¤ëŠ” ì—´ë“¤ ì¤‘ ê°€ì¥ ì˜¤ë¥¸ìª½"ì„ ì„ íƒí•œë‹¤.
    4) 7~9í˜ì´ì§€ëŠ” í—¤ë”ê°€ ì—†ìœ¼ë¯€ë¡œ, ì§ì „ col_map(í—¤ë” í…Œì´ë¸”)ì˜ ìœ„ì¹˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤.
    """

    results: List[Dict[str, str]] = []

    # ì§ì „ì— ë³¸ "ì™„ì „í•œ í—¤ë”" í…Œì´ë¸” ì •ë³´
    last_col_map: Dict[str, int] | None = None
    last_ncols: int | None = None

    current_type = ""
    current_abbr = ""

    def looks_like_floor(s: str) -> bool:
        if not s:
            return False
        t = str(s).replace(" ", "")
        return "ì¸µ" in t and "ë™" not in t and "í˜¸" not in t

    def detect_price_col_by_numbers(df2: pd.DataFrame) -> int | None:
        """
        df2: í—¤ë” í¬í•¨ëœ í…Œì´ë¸” (0í–‰ = í—¤ë”)
        ê° ì—´ë³„ë¡œ ìˆ«ì íŒ¨í„´ì„ ë³´ê³  'ê¸ˆì•¡ ì—´' í›„ë³´ë¥¼ ì°¾ëŠ”ë‹¤.
        - ìˆ«ìê°€ 3ê±´ ì´ìƒ ë‚˜ì˜¤ê³ 
        - ìˆ«ì ìë¦¬ìˆ˜ì˜ ì¤‘ì•™ê°’ì´ 7ìë¦¬ ì´ìƒì´ë©´ 'ê¸ˆì•¡ ì—´'ë¡œ ê°„ì£¼
        ì—¬ëŸ¬ ê°œë©´ ê°€ì¥ ì˜¤ë¥¸ìª½ ì—´ì„ ì„ íƒ
        """
        ncols = df2.shape[1]
        candidate_cols: List[int] = []

        for c in range(ncols):
            nums: List[int] = []
            for r in range(1, df2.shape[0]):  # 0í–‰ì€ í—¤ë”
                val = str(df2.iloc[r, c]).strip()
                digits = re.sub(r"[^0-9]", "", val)
                if not digits:
                    continue
                try:
                    num = int(digits)
                except ValueError:
                    continue
                nums.append(num)

            if len(nums) < 3:
                continue

            # ìë¦¬ìˆ˜ ì¤‘ì•™ê°’ ê³„ì‚°
            lens = sorted(len(str(x)) for x in nums)
            med_len = lens[len(lens) // 2]

            if med_len >= 7:  # ìµœì†Œ 1,000ë§Œ ì´ìƒìœ¼ë¡œ ê°€ì •
                candidate_cols.append(c)

        if not candidate_cols:
            return None
        return max(candidate_cols)  # ê°€ì¥ ì˜¤ë¥¸ìª½ ì—´

    for page_idx, page in enumerate(pdf.pages):
        tables = page.extract_tables() or []
        for table in tables:
            if not table or len(table) < 2:
                continue

            df = pd.DataFrame(table).fillna("")
            all_txt = "".join(df.astype(str).values.ravel())

            # 1) ì˜µì…˜/ì„ íƒì‚¬ì–‘ í‘œ í†µì§¸ë¡œ ì œì™¸
            if any(k in all_txt for k in ["ì˜µì…˜", "ì„ íƒí’ˆëª©", "ì„ íƒì‚¬ì–‘"]):
                continue

            # --------------------------
            # A. í—¤ë”(ì£¼íƒí˜• + ì•½ì‹í‘œê¸°) í–‰ ì°¾ê¸°
            # --------------------------
            header_idx = None
            for i, row in df.iterrows():
                row_txt = "".join(str(x) for x in row.tolist())
                if "ì£¼íƒí˜•" in row_txt and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹ í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt):
                    header_idx = i
                    break

            col_map: Dict[str, int] = {}

            if header_idx is not None:
                # 6í˜ì´ì§€ì²˜ëŸ¼ í—¤ë”ê°€ ìˆëŠ” ì •ì‹ í‘œ
                df2 = df.iloc[header_idx:].reset_index(drop=True)
                ncols = df2.shape[1]

                for c in range(ncols):
                    hdr = "".join(df2.iloc[0:4, c].astype(str).tolist())
                    h = hdr.replace(" ", "").replace("\n", "")

                    if "ì£¼íƒí˜•" in h:
                        col_map["ì£¼íƒí˜•"] = c
                    elif "ì•½ì‹í‘œê¸°" in h or "ì•½ì‹í‘œì‹œ" in h or "ì•½ì‹" in h:
                        col_map["ì•½ì‹í‘œê¸°"] = c
                    elif ("ë™" in h and "í˜¸" in h) or "ë™/í˜¸" in h:
                        col_map["ë™/í˜¸ë³„"] = c
                    elif "ì¸µêµ¬ë¶„" in h or ("ì¸µ" in h and "êµ¬ë¶„" in h):
                        col_map["ì¸µêµ¬ë¶„"] = c
                    elif "í•´ë‹¹ì„¸ëŒ€" in h:
                        col_map["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] = c

                # ğŸ” í—¤ë” í…ìŠ¤íŠ¸ì™€ ë¬´ê´€í•˜ê²Œ, ìˆ«ì íŒ¨í„´ìœ¼ë¡œ ê³µê¸‰ê¸ˆì•¡ ì—´ ì°¾ê¸°
                price_idx = detect_price_col_by_numbers(df2)
                if price_idx is None:
                    # ê¸ˆì•¡ ì—´ì„ ëª» ì°¾ìœ¼ë©´ ì´ í‘œëŠ” ìŠ¤í‚µ
                    last_col_map = None
                    last_ncols = None
                    continue

                col_map["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] = price_idx

                last_col_map = col_map.copy()
                last_ncols = ncols

            else:
                # --------------------------
                # B. í—¤ë” ì—†ëŠ” ì´ì–´ì§€ëŠ” í‘œ (7~9í˜ì´ì§€ ë“±)
                # --------------------------
                if not last_col_map:
                    continue

                df2 = df.reset_index(drop=True)
                ncols = df2.shape[1]
                col_map = last_col_map.copy()

                # 6í˜ì´ì§€ë³´ë‹¤ ì—´ì´ 1ê°œ ì ìœ¼ë©´ â†’ "ë™/í˜¸ë³„" ì—´ì´ ë¹ ì¡Œë‹¤ê³  ë³´ê³  ë³´ì •
                if last_ncols is not None and ncols == last_ncols - 1 and "ë™/í˜¸ë³„" in col_map:
                    removed_idx = col_map["ë™/í˜¸ë³„"]
                    col_map.pop("ë™/í˜¸ë³„")
                    for k, v in list(col_map.items()):
                        if v > removed_idx:
                            col_map[k] = v - 1
                elif last_ncols is not None and ncols != last_ncols:
                    # êµ¬ì¡°ê°€ ë„ˆë¬´ ë‹¤ë¥´ë©´ ìŠ¤í‚µ
                    continue

            # --------------------------
            # ë°ì´í„° í–‰ íŒŒì‹±
            # --------------------------
            def get_val(row, idx: int | None) -> str:
                if idx is None or idx < 0 or idx >= len(row):
                    return ""
                return str(row.iloc[idx]).strip()

            start_row = 1 if header_idx is not None else 0

            for r in range(start_row, df2.shape[0]):
                row = df2.iloc[r]
                row_txt = "".join(str(x) for x in row.tolist())

                # ì¤‘ê°„ì— ë˜ ë‚˜ì˜¤ëŠ” í—¤ë” / í•©ê³„ / ì „íƒ€ì… / ë¶€ë¶„ ë“±ì€ ìŠ¤í‚µ
                if "ì£¼íƒí˜•" in row_txt and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt):
                    continue
                if any(k in row_txt for k in ["í•©ê³„", "ì „íƒ€ì…", "ë¶€ë¶„"]):
                    continue

                # íƒ€ì… / ì•½ì‹ forward-fill
                v_type = get_val(row, col_map.get("ì£¼íƒí˜•"))
                if v_type:
                    current_type = v_type

                v_abbr = get_val(row, col_map.get("ì•½ì‹í‘œê¸°"))
                if v_abbr:
                    current_abbr = v_abbr

                dongho = get_val(row, col_map.get("ë™/í˜¸ë³„"))
                floor = get_val(row, col_map.get("ì¸µêµ¬ë¶„"))

                # ë™/í˜¸ ì¹¸ì— '1ì¸µ', '2ì¸µ' ê°™ì€ ê°’ì´ ë“¤ì–´ê°„ ê²½ìš° â†’ ì¸µêµ¬ë¶„ìœ¼ë¡œ ë³´ì •
                if dongho and looks_like_floor(dongho) and not looks_like_floor(floor):
                    floor = dongho
                    dongho = ""

                # ì¸µêµ¬ë¶„ì— 'ì¸µ' ê¸€ì ì—†ìœ¼ë©´ ë¶™ì—¬ì£¼ê¸° (ì˜ˆ: '1' â†’ '1ì¸µ')
                if floor:
                    fv = floor.replace(" ", "")
                    if "ì¸µ" not in fv and re.search(r"\d", fv):
                        floor = fv + "ì¸µ"

                # í•´ë‹¹ì„¸ëŒ€ìˆ˜: 3ìë¦¬ ì´í•˜ ìˆ«ìë§Œ ì¸ì • (1000 ì´ìƒì´ë©´ ê¸ˆì•¡ì¼ ê°€ëŠ¥ì„±ì´ í¼)
                haedang = get_val(row, col_map.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜"))
                if haedang:
                    d = re.sub(r"[^0-9]", "", haedang)
                    if not d or len(d) > 3:
                        haedang = ""

                # ê³µê¸‰ê¸ˆì•¡ ì†Œê³„: 1ì²œë§Œ ì´ìƒ(7ìë¦¬ ì´ìƒ)ë§Œ ì¸ì •
                price = get_val(row, col_map.get("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"))
                if price:
                    pdigits = re.sub(r"[^0-9]", "", price)
                    if not pdigits or len(pdigits) < 7:
                        price = ""

                # ìµœì†Œ ì •ë³´ ì²´í¬
                if not (current_type or current_abbr):
                    continue
                if not price:
                    continue
                if not (dongho or floor or haedang):
                    continue

                rec: Dict[str, str] = {
                    "ì£¼íƒí˜•": current_type,
                    "ì•½ì‹í‘œê¸°": current_abbr,
                    "ë™/í˜¸ë³„": dongho,
                    "ì¸µêµ¬ë¶„": floor,
                    "í•´ë‹¹ì„¸ëŒ€ìˆ˜": haedang,
                    "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„": price,
                }
                results.append(rec)

    return results

# ============================
# Streamlit UI
# ============================
st.set_page_config(page_title="ì…ì£¼ìëª¨ì§‘ê³µê³  ë¶„ì„ê¸°", layout="wide")

st.sidebar.title("ğŸ“‚ PDF ì—…ë¡œë“œ")
uploaded = st.sidebar.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])

st.title("ğŸ¢ ì…ì£¼ìëª¨ì§‘ê³µê³  ë¶„ì„ê¸° (ìë™ ë¶„ì„)")

if uploaded:
    uploaded.seek(0)
    text = ""
    with pdfplumber.open(uploaded) as pdf:
        for p in pdf.pages:
            text += (p.extract_text() or "") + "\n"

    text = filter_irrelevant_sections(text)

    uploaded.seek(0)
    with pdfplumber.open(uploaded) as pdf:
        schedule = extract_schedule_from_table(pdf)
        table_company = extract_company_from_table(pdf, text)
        supply_rows = extract_supply_target_from_tables(pdf)
        price_rows = extract_price_table_from_tables(pdf)


    core = extract_core_info(text)
    loan_cond = extract_loan_condition(text)
    move_in = extract_move_in_date(text)

    st.subheader("ğŸ§  ìë™ ë¶„ì„ ê²°ê³¼")

    st.markdown(f"**ğŸ¢ ë‹¨ì§€ëª…:** {parse_complex_name(text) or 'ì •ë³´ ì—†ìŒ'}")
    st.markdown(f"**ğŸ“ ê³µê¸‰ ìœ„ì¹˜:** {parse_location(text) or 'ì •ë³´ ì—†ìŒ'}")

    st.subheader("ğŸ“Œ í•µì‹¬ ì •ë³´ ìš”ì•½")
    st.write(f"- **ê³µê¸‰ê·œëª¨:** {core.get('ê³µê¸‰ê·œëª¨') or 'ì •ë³´ ì—†ìŒ'}")
    st.write(f"- **ì…ì£¼ì˜ˆì •ì¼:** {move_in or 'ì •ë³´ ì—†ìŒ'}")

    final_siheng = table_company.get("ì‹œí–‰ì‚¬") or core.get("ì‹œí–‰ì‚¬")
    st.write(f"- **ì‹œí–‰ì‚¬:** {final_siheng or 'ì •ë³´ ì—†ìŒ'}")

    final_sigong = table_company.get("ì‹œê³µì‚¬") or core.get("ì‹œê³µì‚¬")
    st.write(f"- **ì‹œê³µì‚¬:** {final_sigong or 'ì •ë³´ ì—†ìŒ'}")

    final_agency = table_company.get("ë¶„ì–‘ëŒ€í–‰ì‚¬")
    if final_agency:
        st.write(f"- **ë¶„ì–‘ëŒ€í–‰ì‚¬:** {final_agency}")

    st.write(f"- **ì¤‘ë„ê¸ˆ ëŒ€ì¶œ ì¡°ê±´:** {loan_cond or 'ì •ë³´ ì—†ìŒ'}")

    st.subheader("ğŸ“… ì²­ì•½ ì¼ì • ìë™ ë¶„ë¥˜")

    order = [
        "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ë‹¹ì²¨ìë°œí‘œì¼",
        "ì„œë¥˜ì ‘ìˆ˜",
        "ê³„ì•½ì²´ê²°",
    ]

    rows = []
    for key in order:
        val = schedule.get(key)
        rows.append({"í•­ëª©": key, "ì¼ì •": val or "ì •ë³´ ì—†ìŒ"})
        st.write(f"- **{key}**: {val or 'ì •ë³´ ì—†ìŒ'}")

    df_schedule = pd.DataFrame(rows)
    st.table(df_schedule)

    st.subheader("ğŸ  ê³µê¸‰ëŒ€ìƒ (íƒ€ì…ë³„ ìš”ì•½)")
    if supply_rows:
        df_supply = pd.DataFrame(supply_rows)
        st.table(df_supply)
    else:
        st.info("ê³µê¸‰ëŒ€ìƒ í‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.subheader("ğŸ’° ê³µê¸‰ê¸ˆì•¡í‘œ (ë™Â·í˜¸Â·ì¸µë³„)")
    if price_rows:
        df_price = pd.DataFrame(price_rows)
        st.table(df_price)
    else:
        st.info("ê³µê¸‰ê¸ˆì•¡í‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    complex_name = parse_complex_name(text) or ""
    location = parse_location(text) or ""

    # ì—‘ì…€ìš©ìœ¼ë¡œë„ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì •ë¦¬ (í˜¹ì‹œë¼ë„ ìƒê¸¸ ê²½ìš° ëŒ€ë¹„)
    clean_price_rows = []
    for row in price_rows:
        clean = {
            "ì£¼íƒí˜•": row.get("ì£¼íƒí˜•", ""),
            "ì•½ì‹í‘œê¸°": row.get("ì•½ì‹í‘œê¸°", ""),
            "ë™/í˜¸ë³„": row.get("ë™/í˜¸ë³„", ""),
            "ì¸µêµ¬ë¶„": row.get("ì¸µêµ¬ë¶„", ""),
            "í•´ë‹¹ì„¸ëŒ€ìˆ˜": row.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜", ""),
            "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„": row.get("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„", ""),
        }
        clean_price_rows.append(clean)

    excel_bytes = make_excel_file(
        complex_name=complex_name,
        location=location,
        core=core,
        move_in=move_in,
        final_siheng=final_siheng,
        final_sigong=final_sigong,
        final_agency=final_agency,
        loan_cond=loan_cond,
        schedule_rows=rows,
        supply_rows=supply_rows,
        price_rows=clean_price_rows,
    )

    st.download_button(
        label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=excel_bytes,
        file_name=f"{complex_name or 'ë¶„ì–‘ë‹¨ì§€'}_ëª¨ì§‘ê³µê³ _ìë™ë¶„ì„.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

else:
    st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
