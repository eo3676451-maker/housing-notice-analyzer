import streamlit as st
import pdfplumber
import re
from io import BytesIO
from datetime import datetime
import pandas as pd
from typing import Dict, List, Tuple
from collections import defaultdict

# ============================
#  ê³µí†µ ìœ í‹¸
# ============================
def parse_ymd(date_str: str):
    try:
        return datetime.strptime(date_str, "%Y.%m.%d").date()
    except:
        return None


# ============================
#  ë‹¨ì§€ëª… ì¶”ì¶œ
# ============================
def parse_complex_name(text: str):
    raw = None
    for line in text.splitlines():
        line = line.strip()
        if "ì…ì£¼ìëª¨ì§‘ê³µê³ " in line:
            raw = line.replace("ì…ì£¼ìëª¨ì§‘ê³µê³ ", "").strip()
            break

    if not raw:
        return None

    name = re.sub(r"\s+", " ", raw)
    name = name.strip(" ,Â·-")
    return name or None


# ============================
#  ê³µê¸‰ìœ„ì¹˜ ì¶”ì¶œ
# ============================
def parse_location(text: str):
    keywords = ["ê³µê¸‰ìœ„ì¹˜", "ì‚¬ì—…ìœ„ì¹˜", "ê±´ì„¤ìœ„ì¹˜", "ëŒ€ì§€ìœ„ì¹˜"]
    for line in text.splitlines():
        for key in keywords:
            if key in line:
                cleaned = line.replace(key, "")
                cleaned = cleaned.replace(":", "")
                cleaned = cleaned.replace("â– ", "")
                cleaned = cleaned.replace("ìœ„ì¹˜", "").strip()
                cleaned = re.sub(r"\s+", " ", cleaned)
                return cleaned
    return None


# ============================
#  ë¶ˆí•„ìš” ë¬¸ë‹¨(ìœ ì˜ì‚¬í•­Â·ë¬´ì£¼íƒê¸°ê°„ ë“±) ì œê±°
# ============================
def filter_irrelevant_sections(text: str) -> str:
    """
    ëª¨ì§‘ê³µê³  ì¤‘ 4~7, 11í•­ëª©ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ”
    'ìœ ì˜ì‚¬í•­/ë¬´ì£¼íƒê¸°ê°„ ì ìš©ê¸°ì¤€/ê¸°íƒ€ ì•ˆë‚´' ë“±ì€
    í•µì‹¬ì •ë³´ ì¶”ì¶œì— ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ë¶„ì„ í…ìŠ¤íŠ¸ì—ì„œ ì œê±°í•œë‹¤.
    """
    remove_keywords = [
        "ë¬´ì£¼íƒê¸°ê°„ ì ìš©ê¸°ì¤€",
        "ë¬´ì£¼íƒ ê¸°ê°„ ì ìš©ê¸°ì¤€",
        "ë¬´ì£¼íƒê¸°ê°„ ì‚°ì •ê¸°ì¤€",
        "ì²­ì•½ ì‹œ ìœ ì˜ì‚¬í•­",
        "ì²­ì•½ì‹œ ìœ ì˜ì‚¬í•­",
        "ìœ ì˜ì‚¬í•­",
        "ê¸°íƒ€ ì‚¬í•­",
        "ê¸°íƒ€ì‚¬í•­",
        "ê³µê¸‰(ë¶„ì–‘)ê³„ì•½ì— ê´€í•œ ìœ ì˜ì‚¬í•­",
        "ê³„ì•½ì²´ê²°ì‹œ ìœ ì˜ì‚¬í•­",
    ]

    filtered_lines = []
    for line in text.splitlines():
        s = line.strip()
        if any(k in s for k in remove_keywords):
            continue
        filtered_lines.append(line)

    return "\n".join(filtered_lines)


# ============================
#  íšŒì‚¬ëª… ì •ê·œí™” + íŒë³„ ìœ í‹¸
# ============================
def normalize_company_name(name: str) -> str:
    if not name:
        return ""
    name = str(name)

    name = name.replace("\n", " ")
    name = re.sub(r"\s+", " ", name).strip()

    name = name.lstrip("â€»*â€¢-Â·[]() ")

    name = name.replace(" (ì£¼)", "(ì£¼)").replace("(ì£¼) ", "(ì£¼)")
    name = name.replace(" ãˆœ", "ãˆœ").replace("ãˆœ ", "ãˆœ")

    if name.endswith("(ì£¼"):
        name = name + ")"
    if re.search(r"\(ì£¼$", name):
        name = name + ")"

    if "â€»" in name:
        name = name.split("â€»", 1)[0].strip()

    return name.strip()


COMPANY_HINT_KEYWORDS = [
    "ì¡°í•©", "ê±´ì„¤", "ì£¼ì‹íšŒì‚¬", "ãˆœ", "(ì£¼)", "ê°œë°œ",
    "ë””ì•¤ì”¨", "ë””ì—”ì”¨", "ì‚°ì—…", "ì—”ì§€ë‹ˆì–´ë§",
    "í™€ë”©ìŠ¤", "íˆ¬ì", "ê³µì‚¬", "ê¸°ì—…", "ì£¼íƒë„ì‹œ",
]


def looks_like_company(name: str) -> bool:
    if not name:
        return False
    name = name.strip()
    if len(name) > 30:
        return False

    bad_endings = ["ê¸°ì¤€", "ì ìš©ê¸°ì¤€", "ì ìš© ê¸°ì¤€", "ì‚°ì •ê¸°ì¤€"]
    if any(name.endswith(be) for be in bad_endings):
        return False

    strong_keywords = ["ì¡°í•©", "ê±´ì„¤", "ì£¼ì‹íšŒì‚¬", "ãˆœ", "(ì£¼)", "ê°œë°œ", "ê³µì‚¬", "ê¸°ì—…"]
    if "ê¸°ê°„" in name and not any(k in name for k in strong_keywords):
        return False

    if any(word in name for word in ["ê´‘ì—­ì‹œ", "íŠ¹ë³„ì‹œ", "ì‹œ ", "êµ° ", "êµ¬ ", "ë™ ", "ë¡œ ", "ê¸¸ "]):
        if not any(k in name for k in COMPANY_HINT_KEYWORDS):
            return False

    return any(k in name for k in COMPANY_HINT_KEYWORDS)


# ============================
#  í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹œí–‰/ì‹œê³µ/ë¶„ì–‘ ì¶”ì¶œ
# ============================
def extract_companies_from_text(text: str) -> Dict[str, List[str]]:
    result = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }

    norm = text.replace("ï¼š", ":")
    norm = re.sub(r"\s+", " ", norm)

    patterns = {
        "ì‹œí–‰ì‚¬": [
            r"(?:ì‚¬ì—…ì£¼ì²´|ì‹œí–‰ì|ì‹œí–‰ì‚¬)\s*[:]\s*([^\n:]+)",
        ],
        "ì‹œê³µì‚¬": [
            r"(?:ì‹œê³µì|ì‹œê³µì‚¬|ì‹œê³µ)\s*[:]\s*([^\n:]+)",
        ],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [
            r"(?:ë¶„ì–‘ëŒ€í–‰ì‚¬|ë¶„ì–‘ëŒ€í–‰|ë¶„ì–‘ëŒ€ë¦¬ì )\s*[:]\s*([^\n:]+)",
        ],
    }

    for role, pats in patterns.items():
        for pat in pats:
            for m in re.finditer(pat, norm):
                name = normalize_company_name(m.group(1))
                if looks_like_company(name) and name not in result[role]:
                    result[role].append(name)

    simple_patterns = {
        "ì‹œí–‰ì‚¬": [
            r"(?:ì‚¬ì—…ì£¼ì²´|ì‹œí–‰ì|ì‹œí–‰ì‚¬)\s+([^\n:]+)",
        ],
        "ì‹œê³µì‚¬": [
            r"(?:ì‹œê³µì|ì‹œê³µì‚¬|ì‹œê³µ)\s+([^\n:]+)",
        ],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [
            r"(?:ë¶„ì–‘ëŒ€í–‰ì‚¬|ë¶„ì–‘ëŒ€í–‰|ë¶„ì–‘ëŒ€ë¦¬ì )\s+([^\n:]+)",
        ],
    }

    for role, pats in simple_patterns.items():
        for pat in pats:
            for m in re.finditer(pat, norm):
                name = normalize_company_name(m.group(1))
                if looks_like_company(name) and name not in result[role]:
                    result[role].append(name)

    combo_pattern = r"(ì‹œí–‰|ì‹œê³µ|ë¶„ì–‘ëŒ€í–‰)\s*[: ]\s*([^/]+)"
    for m in re.finditer(combo_pattern, norm):
        key = m.group(1)
        name = normalize_company_name(m.group(2))
        if "ì‹œí–‰" in key:
            role = "ì‹œí–‰ì‚¬"
        elif "ì‹œê³µ" in key:
            role = "ì‹œê³µì‚¬"
        else:
            role = "ë¶„ì–‘ëŒ€í–‰ì‚¬"
        if looks_like_company(name) and name not in result[role]:
            result[role].append(name)

    return result


# ============================
#  í•µì‹¬ ì •ë³´(ê³µê¸‰ê·œëª¨ + í…ìŠ¤íŠ¸ ë°±ì—…ìš© ì‹œí–‰/ì‹œê³µ) ì¶”ì¶œ
# ============================
def extract_core_info(text: str):
    info = {
        "ê³µê¸‰ê·œëª¨": None,
        "ì‹œí–‰ì‚¬": None,
        "ì‹œê³µì‚¬": None,
    }

    for line in text.splitlines():
        s = line.strip()
        if not s:
            continue

        if not info["ê³µê¸‰ê·œëª¨"] and ("ê³µê¸‰ê·œëª¨" in s or "ì´ ê³µê¸‰ì„¸ëŒ€ìˆ˜" in s):
            cleaned = s
            cleaned = cleaned.replace("â– ", "")
            cleaned = cleaned.replace("â—", "")
            cleaned = cleaned.replace("ê³µê¸‰ê·œëª¨", "")
            cleaned = cleaned.replace("ì´ ê³µê¸‰ì„¸ëŒ€ìˆ˜", "")
            cleaned = cleaned.replace(":", "")
            cleaned = cleaned.strip()
            info["ê³µê¸‰ê·œëª¨"] = cleaned
            continue

        if not info["ì‹œí–‰ì‚¬"] and ("ì‹œí–‰ì" in s or "ì‹œí–‰ì‚¬" in s):
            cleaned = s
            cleaned = cleaned.replace("â– ", "").replace("â—", "")
            cleaned = cleaned.replace("ì‹œí–‰ì", "").replace("ì‹œí–‰ì‚¬", "")
            cleaned = cleaned.replace(":", "")
            cleaned = cleaned.strip()

            cleaned = normalize_company_name(cleaned)
            if looks_like_company(cleaned):
                info["ì‹œí–‰ì‚¬"] = cleaned
            continue

        if not info["ì‹œê³µì‚¬"] and ("ì‹œê³µì" in s or "ì‹œê³µì‚¬" in s):
            cleaned = s
            cleaned = cleaned.replace("â– ", "").replace("â—", "")
            cleaned = cleaned.replace("ì‹œê³µì", "").replace("ì‹œê³µì‚¬", "")
            cleaned = cleaned.replace(":", "")
            cleaned = cleaned.strip()

            cleaned = normalize_company_name(cleaned)
            if looks_like_company(cleaned):
                info["ì‹œê³µì‚¬"] = cleaned
            continue

    return info


# ============================
#  ì…ì£¼ ì˜ˆì •ì¼ ì¶”ì¶œ
# ============================
def extract_move_in_date(text: str) -> str | None:
    candidate_lines: List[str] = []

    for line in text.splitlines():
        s = line.strip()
        if not s:
            continue

        no_space = s.replace(" ", "")

        if any(k in no_space for k in ["ì…ì£¼ì‹œê¸°", "ì…ì£¼ì‹œê¸°", "ì…ì£¼ì˜ˆì •", "ì…ì£¼ì˜ˆì •ì¼"]):
            candidate_lines.append(s)

    for s in candidate_lines:
        m = re.search(r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”", s)
        if m:
            year = int(m.group(1))
            month = int(m.group(2))
            return f"{year}ë…„ {month}ì›”"

        m2 = re.search(r"(\d{4})\.(\d{1,2})", s)
        if m2:
            year = int(m2.group(1))
            month = int(m2.group(2))
            return f"{year}ë…„ {month}ì›”"

    if candidate_lines:
        first = candidate_lines[0]
        return first[:40] + "..." if len(first) > 40 else first

    return None


# ============================
#  í‘œ ê¸°ë°˜ íšŒì‚¬ì •ë³´ ì¶”ì¶œ ìœ í‹¸
# ============================
ROLE_KEYWORDS = {
    "ì‹œí–‰ì‚¬": ["ì‚¬ì—…ì£¼ì²´", "ì‹œí–‰ì", "ì‹œí–‰ì‚¬", "ì‚¬ì—…ì‹œí–‰ì"],
    "ì‹œê³µì‚¬": ["ì‹œê³µì‚¬", "ì‹œê³µì", "ì‹œê³µ"],
    "ë¶„ì–‘ëŒ€í–‰ì‚¬": ["ë¶„ì–‘ëŒ€í–‰ì‚¬", "ë¶„ì–‘ëŒ€í–‰", "ë¶„ì–‘ëŒ€ë¦¬ì ", "ìœ„íƒì‚¬"],
}


def detect_role_from_header(text: str) -> List[str]:
    roles = []
    t = text.replace(" ", "")
    for role, keywords in ROLE_KEYWORDS.items():
        if any(k in t for k in keywords):
            roles.append(role)
    return roles


def extract_from_vertical_label_table(
    df: pd.DataFrame,
    page_idx: int,
) -> Dict[str, List[Tuple[str, int]]]:
    res = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }
    if df.empty:
        return res

    df = df.fillna("")
    label_col = df.iloc[:, 0].astype(str)

    for i, label in enumerate(label_col):
        roles = detect_role_from_header(label)
        if not roles:
            continue
        row = df.iloc[i, 1:]
        candidates = [normalize_company_name(v) for v in row if str(v).strip()]
        for role in roles:
            for c in candidates:
                if looks_like_company(c):
                    res[role].append((c, page_idx))

    return res


def extract_from_horizontal_header_table(
    df: pd.DataFrame,
    page_idx: int,
) -> Dict[str, List[Tuple[str, int]]]:
    res = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }
    if df.empty or len(df) < 2:
        return res

    df = df.fillna("")
    header = df.iloc[0].astype(str).tolist()
    body = df[1:]

    for col_idx, h in enumerate(header):
        roles = detect_role_from_header(h)
        if not roles:
            continue
        col_values = body.iloc[:, col_idx].astype(str)
        candidates = [
            normalize_company_name(v)
            for v in col_values
            if str(v).strip()
        ]
        for role in roles:
            for c in candidates:
                if looks_like_company(c):
                    res[role].append((c, page_idx))

    return res


def extract_company_candidates_from_pdf(pdf) -> Tuple[Dict[str, List[Tuple[str, int]]], int]:
    result = {
        "ì‹œí–‰ì‚¬": [],
        "ì‹œê³µì‚¬": [],
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": [],
    }

    last_page_idx = len(pdf.pages) - 1 if pdf.pages else 0

    for page_idx, page in enumerate(pdf.pages):
        tables = page.extract_tables() or []
        for table in tables:
            if not table:
                continue
            df = pd.DataFrame(table)
            if df.empty:
                continue

            vertical = extract_from_vertical_label_table(df, page_idx)
            horizontal = extract_from_horizontal_header_table(df, page_idx)

            for role in result.keys():
                result[role].extend(vertical.get(role, []))
                result[role].extend(horizontal.get(role, []))

    return result, last_page_idx


def choose_final_company(
    text_candidates: Dict[str, List[str]],
    table_candidates: Dict[str, List[Tuple[str, int]]],
    last_page_idx: int = None,
) -> Dict[str, str]:
    scores: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))

    for role, vals in table_candidates.items():
        for name, page_idx in vals:
            if not name:
                continue
            base = 3
            bonus = 0
            if last_page_idx is not None and page_idx == last_page_idx:
                bonus += 2
            scores[role][name] += base + bonus

    for role, names in text_candidates.items():
        for name in names:
            if not name:
                continue
            scores[role][name] += 2

    final = {
        "ì‹œí–‰ì‚¬": "",
        "ì‹œê³µì‚¬": "",
        "ë¶„ì–‘ëŒ€í–‰ì‚¬": "",
    }

    for role, name_scores in scores.items():
        if not name_scores:
            continue
        sorted_candidates = sorted(
            name_scores.items(),
            key=lambda x: (x[1], len(x[0])),
            reverse=True,
        )
        final[role] = sorted_candidates[0][0]

    return final


# ============================
#  í…ìŠ¤íŠ¸ + í‘œ ê¸°ë°˜ í†µí•© ì¶”ì¶œ
# ============================
def extract_company_from_table(pdf, text: str) -> Dict[str, str]:
    text_candidates = extract_companies_from_text(text)
    table_candidates, last_page_idx = extract_company_candidates_from_pdf(pdf)
    final = choose_final_company(text_candidates, table_candidates, last_page_idx)
    return final


# ============================
#  ì¤‘ë„ê¸ˆ ëŒ€ì¶œ ì¡°ê±´ ì¶”ì¶œ
# ============================
def extract_loan_condition(text: str):
    condition = None
    related_lines = []

    for line in text.splitlines():
        s = line.strip()
        if "ì¤‘ë„ê¸ˆ" in s and "ëŒ€ì¶œ" in s:
            related_lines.append(s)
        elif "ì¤‘ë„ê¸ˆ" in s and "ì´ì" in s:
            related_lines.append(s)

    joined = " ".join(related_lines)

    if "ì´ìí›„ë¶ˆì œ" in joined or "ì´ì í›„ë¶ˆì œ" in joined:
        condition = "ì´ìí›„ë¶ˆì œ"
    elif "ë¬´ì´ì" in joined:
        condition = "ë¬´ì´ì"

    if not condition and joined:
        condition = joined

    return condition


# ============================
#  ì—‘ì…€ ë‹¤ìš´ë¡œë“œìš© íŒŒì¼ ìƒì„±
# ============================
def make_excel_file(
    complex_name: str,
    location: str,
    core: dict,
    move_in: str | None,
    final_siheng: str | None,
    final_sigong: str | None,
    final_agency: str | None,
    loan_cond: str | None,
    schedule_rows: list,
    supply_rows: list,
    price_rows: list,
) -> BytesIO:
    summary_rows = [
        {"í•­ëª©": "ë‹¨ì§€ëª…", "ê°’": complex_name},
        {"í•­ëª©": "ê³µê¸‰ìœ„ì¹˜", "ê°’": location},
        {"í•­ëª©": "ê³µê¸‰ê·œëª¨", "ê°’": core.get("ê³µê¸‰ê·œëª¨") or ""},
        {"í•­ëª©": "ì…ì£¼ì˜ˆì •ì¼", "ê°’": move_in or ""},
        {"í•­ëª©": "ì‹œí–‰ì‚¬", "ê°’": final_siheng or ""},
        {"í•­ëª©": "ì‹œê³µì‚¬", "ê°’": final_sigong or ""},
        {"í•­ëª©": "ë¶„ì–‘ëŒ€í–‰ì‚¬", "ê°’": final_agency or ""},
        {"í•­ëª©": "ì¤‘ë„ê¸ˆ ëŒ€ì¶œ ì¡°ê±´", "ê°’": loan_cond or ""},
    ]

    for row in schedule_rows:
        summary_rows.append({"í•­ëª©": row.get("í•­ëª©", ""), "ê°’": row.get("ì¼ì •", "")})

    df_summary = pd.DataFrame(summary_rows)
    df_supply = pd.DataFrame(supply_rows) if supply_rows else pd.DataFrame()
    df_price = pd.DataFrame(price_rows) if price_rows else pd.DataFrame()

    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        sheet_name = "ëª¨ì§‘ê³µê³ "

        df_summary.to_excel(writer, index=False, sheet_name=sheet_name, startrow=0)

        start_row = len(df_summary) + 2

        if not df_supply.empty:
            df_supply.to_excel(writer, index=False, sheet_name=sheet_name, startrow=start_row)
            start_row += len(df_supply) + 2

        if not df_price.empty:
            df_price.to_excel(writer, index=False, sheet_name=sheet_name, startrow=start_row)

    output.seek(0)
    return output


# ============================
#  í‘œì—ì„œ ì²­ì•½ ì¼ì • ì¶”ì¶œ
# ============================
def extract_schedule_from_table(pdf):
    schedule = {
        "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼": None,
        "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼": None,
        "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼": None,
        "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼": None,
        "ë‹¹ì²¨ìë°œí‘œì¼": None,
        "ì„œë¥˜ì ‘ìˆ˜": None,
        "ê³„ì•½ì²´ê²°": None,
    }

    header_map = {
        "ì…ì£¼ìëª¨ì§‘ê³µê³ ": "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "ì…ì£¼ì ëª¨ì§‘ê³µê³ ": "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "íŠ¹ë³„ê³µê¸‰ì ‘ìˆ˜": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "íŠ¹ë³„ê³µê¸‰ ì‹ ì²­": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜": "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "1ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "1ìˆœìœ„": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "2ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "2ìˆœìœ„": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜": "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ë‹¹ì²¨ìë°œí‘œì¼": "ë‹¹ì²¨ìë°œí‘œì¼",
        "ë‹¹ì²¨ì ë°œí‘œ": "ë‹¹ì²¨ìë°œí‘œì¼",
        "ì„œë¥˜ì ‘ìˆ˜": "ì„œë¥˜ì ‘ìˆ˜",
        "ì •ë‹¹ê³„ì•½": "ê³„ì•½ì²´ê²°",
        "ê³„ì•½ì²´ê²°": "ê³„ì•½ì²´ê²°",
    }

    date_pattern = r"\d{4}\.\d{1,2}\.\d{1,2}"

    def update(label, new_val):
        old = schedule.get(label)
        if not old:
            schedule[label] = new_val
            return

        try:
            old_d = datetime.strptime(re.findall(date_pattern, old)[0], "%Y.%m.%d")
            new_d = datetime.strptime(re.findall(date_pattern, new_val)[0], "%Y.%m.%d")
            if new_d > old_d:
                schedule[label] = new_val
        except:
            pass

    for page in pdf.pages:
        tables = page.extract_tables() or []

        for table in tables:
            if not table:
                continue

            rows = table

            for r, row in enumerate(rows):
                for c, cell in enumerate(row):
                    if not cell:
                        continue
                    cell_t = cell.replace(" ", "")

                    for key, label in header_map.items():
                        if key.replace(" ", "") in cell_t:

                            for rr in range(r + 1, len(rows)):
                                if c >= len(rows[rr]):
                                    continue

                                raw = rows[rr][c] or ""
                                found = re.findall(date_pattern, raw)
                                if not found:
                                    continue

                                if label in ["ì„œë¥˜ì ‘ìˆ˜", "ê³„ì•½ì²´ê²°"] and len(found) >= 2:
                                    update(label, f"{found[0]} ~ {found[-1]}")
                                else:
                                    update(label, found[0])

                                break

    return schedule


# ============================
#  ê³µê¸‰ëŒ€ìƒ(íƒ€ì…ë³„) ì¶”ì¶œ
# ============================
def extract_supply_target_from_tables(pdf) -> List[Dict[str, str]]:
    results: List[Dict[str, str]] = []

    for page in pdf.pages:
        tables = page.extract_tables() or []
        for table in tables:
            if not table or len(table) < 3:
                continue

            df = pd.DataFrame(table).fillna("")
            header_idx = None

            for i, row in df.iterrows():
                row_txt = "".join(str(x) for x in row.tolist())
                if "ì£¼íƒí˜•" in row_txt and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹ í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt):
                    header_idx = i
                    break

            if header_idx is None:
                continue

            df2 = df.iloc[header_idx:].reset_index(drop=True)
            ncols = df2.shape[1]

            col_map: Dict[str, int] = {}
            for c in range(ncols):
                hdr = "".join(df2.iloc[0:4, c].astype(str).tolist())
                hdr = hdr.replace(" ", "").replace("\n", "")

                if "ì£¼íƒí˜•" in hdr:
                    col_map["ì£¼íƒí˜•"] = c
                elif "ì•½ì‹í‘œê¸°" in hdr or "ì•½ì‹í‘œì‹œ" in hdr or "ì•½ì‹" in hdr:
                    col_map["ì•½ì‹í‘œê¸°"] = c
                elif "ì£¼ê±°ì „ìš©ë©´ì " in hdr or ("ì „ìš©" in hdr and "ë©´ì " in hdr):
                    col_map["ì£¼ê±° ì „ìš©ë©´ì "] = c
                elif "ì†Œê³„" in hdr and "ì„¸ëŒ€" not in hdr:
                    col_map["ì£¼íƒê³µê¸‰ë©´ì  ì†Œê³„"] = c
                elif ("ì´ê³µê¸‰" in hdr and "ì„¸ëŒ€ìˆ˜" in hdr) or "ì´ê³µê¸‰ì„¸ëŒ€ìˆ˜" in hdr:
                    col_map["ì´ ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = c
                elif "ì¼ë°˜ê³µê¸‰" in hdr and "ì„¸ëŒ€ìˆ˜" in hdr:
                    col_map["ì¼ë°˜ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = c
                elif "ê¸°ê´€ì¶”ì²œ" in hdr:
                    col_map["ê¸°ê´€ì¶”ì²œ"] = c
                elif "ë‹¤ìë…€" in hdr:
                    col_map["ë‹¤ìë…€ê°€êµ¬"] = c
                elif "ì‹ í˜¼ë¶€ë¶€" in hdr:
                    col_map["ì‹ í˜¼ë¶€ë¶€"] = c
                elif "ë…¸ë¶€ëª¨" in hdr:
                    col_map["ë…¸ë¶€ëª¨ë¶€ì–‘"] = c
                elif "ìƒì• ìµœì´ˆ" in hdr:
                    col_map["ìƒì• ìµœì´ˆ"] = c

            if not col_map:
                continue

            for r in range(1, df2.shape[0]):
                row = df2.iloc[r]
                row_txt = "".join(str(x) for x in row.tolist())

                if "í•©ê³„" in row_txt:
                    continue

                def get_val(key: str) -> str:
                    idx = col_map.get(key)
                    if idx is None or idx >= len(row):
                        return ""
                    return str(row.iloc[idx]).strip()

                rec: Dict[str, str] = {}
                rec["ì£¼íƒí˜•"] = get_val("ì£¼íƒí˜•")
                rec["ì•½ì‹í‘œê¸°"] = get_val("ì•½ì‹í‘œê¸°")
                rec["ì£¼ê±° ì „ìš©ë©´ì "] = get_val("ì£¼ê±° ì „ìš©ë©´ì ")
                rec["ì£¼íƒê³µê¸‰ë©´ì  ì†Œê³„"] = get_val("ì£¼íƒê³µê¸‰ë©´ì  ì†Œê³„")
                rec["ì´ ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = get_val("ì´ ê³µê¸‰ ì„¸ëŒ€ìˆ˜")
                rec["ì¼ë°˜ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = get_val("ì¼ë°˜ê³µê¸‰ ì„¸ëŒ€ìˆ˜")

                special_total = 0
                for k in ["ê¸°ê´€ì¶”ì²œ", "ë‹¤ìë…€ê°€êµ¬", "ì‹ í˜¼ë¶€ë¶€", "ë…¸ë¶€ëª¨ë¶€ì–‘", "ìƒì• ìµœì´ˆ"]:
                    idx = col_map.get(k)
                    if idx is None or idx >= len(row):
                        continue
                    raw = str(row.iloc[idx])
                    num = re.sub(r"[^0-9]", "", raw)
                    if num:
                        special_total += int(num)

                rec["íŠ¹ë³„ê³µê¸‰ ì„¸ëŒ€ìˆ˜"] = str(special_total) if special_total > 0 else ""

                if not (rec.get("ì£¼íƒí˜•") or rec.get("ì•½ì‹í‘œê¸°")):
                    continue
                if ("ì£¼íƒí˜•" in rec.get("ì£¼íƒí˜•", "")) or ("ì•½ì‹" in rec.get("ì•½ì‹í‘œê¸°", "")):
                    continue

                results.append(rec)

            # íƒ€ì…í‘œëŠ” í•œ ë²ˆë§Œ ì°¾ìœ¼ë©´ ì¶©ë¶„í•˜ë‹ˆ, ì²« ë°œê²¬ í›„ ì¢…ë£Œ
            if results:
                return results

    return results


# ============================
#  ê³µê¸‰ê¸ˆì•¡í‘œ ì¶”ì¶œ (ë™Â·í˜¸Â·ì¸µë³„, ì „ì²´ íƒ€ì…)
# ============================
def extract_price_table_from_tables(pdf) -> List[Dict[str, str]]:
    """
    'ê³µê¸‰ê¸ˆì•¡í‘œ'ì—ì„œ
    - ì£¼íƒí˜•
    - ì•½ì‹í‘œê¸°
    - ë™/í˜¸ë³„
    - ì¸µêµ¬ë¶„
    - í•´ë‹¹ì„¸ëŒ€ìˆ˜
    - ê³µê¸‰ê¸ˆì•¡ ì†Œê³„
    ë¥¼ ë½‘ì•„ì˜¨ë‹¤.

    ğŸ”¹ íŠ¹ì§•
    1) ì˜µì…˜í‘œ(ì„ íƒì˜µì…˜, í™•ì¥ë¹„ ë“±)ëŠ” ì „ë¶€ ì œì™¸
    2) 1ê°œ íƒ€ì…ì´ ì—¬ëŸ¬ í˜ì´ì§€/ì—¬ëŸ¬ í…Œì´ë¸”ë¡œ ëŠì–´ì ¸ ìˆì–´ë„ ì´ì–´ì„œ ìˆ˜ì§‘
       (6í˜ì´ì§€ í—¤ë” + 7~9í˜ì´ì§€ ë³¸ë¬¸ì²˜ëŸ¼)
    3) 'ë¶€ë¶„', 'ì „ íƒ€ì…' ê°™ì€ ìš”ì•½í–‰ / ë©´ì í‘œëŠ” ì œê±°
    """

    results: List[Dict[str, str]] = []

    # ì´ì „ì— ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±í•œ "ì™„ì „í•œ í—¤ë”" í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ë§¤í•‘
    last_col_map: Dict[str, int] | None = None
    current_type = ""
    current_abbr = ""

    for page_idx, page in enumerate(pdf.pages):
        tables = page.extract_tables() or []
        for table_idx, table in enumerate(tables):
            if not table or len(table) < 2:
                continue

            df = pd.DataFrame(table).fillna("")
            all_txt = "".join(df.astype(str).values.ravel()).replace(" ", "")

            # 1) ì˜µì…˜/ì„ íƒì‚¬ì–‘ í‘œëŠ” í†µì§¸ë¡œ ìŠ¤í‚µ
            if any(k in all_txt for k in ["ì˜µì…˜", "ì„ íƒí’ˆëª©", "ì„ íƒì‚¬ì–‘"]):
                continue

            # 2) ê³µê¸‰ê¸ˆì•¡í‘œ í›„ë³´ í•„í„°
            has_price = ("ê³µê¸‰ê¸ˆì•¡" in all_txt and "ì†Œê³„" in all_txt)
            has_dongho = ("ë™" in all_txt and "í˜¸" in all_txt) or "ë™/í˜¸" in all_txt
            has_floor = "ì¸µêµ¬ë¶„" in all_txt or ("ì¸µ" in all_txt and "êµ¬ë¶„" in all_txt)
            has_haedang = "í•´ë‹¹ì„¸ëŒ€" in all_txt

            # í—¤ë”(ê³µê¸‰ê¸ˆì•¡ ì†Œê³„)ê°€ í•œ ë²ˆë„ ì•ˆ ë‚˜ì˜¨ ìƒíƒœì—ì„œ has_price=False ë©´ ìŠ¤í‚µ
            if not has_price and not last_col_map:
                continue

            # ë™/ì¸µ/í•´ë‹¹ì„¸ëŒ€ ê´€ë ¨ ë‹¨ì„œê°€ ì „í˜€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ìš”ì•½í‘œì¼ ê°€ëŠ¥ì„±ì´ í¼
            if not (has_dongho or has_floor or has_haedang):
                continue

            # ---------------------------------------------------
            # A. 'ì£¼íƒí˜• + ì•½ì‹í‘œê¸°'ê°€ ê°™ì´ ìˆëŠ” í‘œ (ì™„ì „í•œ í—¤ë”)
            # ---------------------------------------------------
            header_idx = None
            for i, row in df.iterrows():
                row_txt = "".join(str(x) for x in row.tolist())
                if (
                    "ì£¼íƒí˜•" in row_txt
                    and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹ í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt)
                ):
                    header_idx = i
                    break

            col_map: Dict[str, int] = {}

            if header_idx is not None:
                # âœ… "ì™„ì „í•œ í—¤ë”" í…Œì´ë¸” (ì˜ˆ: 6í˜ì´ì§€)
                df2 = df.iloc[header_idx:].reset_index(drop=True)
                ncols = df2.shape[1]

                for c in range(ncols):
                    hdr = "".join(df2.iloc[0:4, c].astype(str).tolist())
                    hdr = hdr.replace(" ", "").replace("\n", "")

                    if "ì£¼íƒí˜•" in hdr:
                        col_map["ì£¼íƒí˜•"] = c
                    elif "ì•½ì‹í‘œê¸°" in hdr or "ì•½ì‹í‘œì‹œ" in hdr or "ì•½ì‹" in hdr:
                        col_map["ì•½ì‹í‘œê¸°"] = c
                    elif ("ë™" in hdr and "í˜¸" in hdr) or "ë™/í˜¸" in hdr:
                        col_map["ë™/í˜¸ë³„"] = c
                    elif "ì¸µêµ¬ë¶„" in hdr or ("ì¸µ" in hdr and "êµ¬ë¶„" in hdr):
                        col_map["ì¸µêµ¬ë¶„"] = c
                    elif "í•´ë‹¹ì„¸ëŒ€ìˆ˜" in hdr or "í•´ë‹¹ì„¸ëŒ€" in hdr:
                        col_map["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] = c
                    elif "ê³µê¸‰ê¸ˆì•¡" in hdr and "ì†Œê³„" in hdr:
                        col_map["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] = c
                    elif "ì†Œê³„" in hdr and "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„" not in col_map:
                        col_map["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] = c

                if not col_map.get("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"):
                    # ê³µê¸‰ê¸ˆì•¡ ìœ„ì¹˜ë¥¼ ëª» ì°¾ìœ¼ë©´ ì´ í‘œëŠ” ìŠ¤í‚µ
                    continue

                # ì´í›„ ì´ì–´ì§€ëŠ” í‘œì—ì„œ ì¬ì‚¬ìš©í•  ê¸°ì¤€
                last_col_map = col_map.copy()

            else:
                # ---------------------------------------------------
                # B. 'í—¤ë” ì—†ëŠ” ì´ì–´ì§€ëŠ” í‘œ' (ex. 7~9í˜ì´ì§€)
                #    â†’ ì§ì „ì— ë³¸ col_map(ì™„ì „í•œ í—¤ë”)ì„ ì¬ì‚¬ìš©
                #    â†’ 7í˜ì´ì§€ì²˜ëŸ¼ ë¨¸ë¦¬ê¸€ í–‰ì´ ì• ë§¤í•œ ê²½ìš°ë¥¼ ìœ„í•´ 0~4í–‰ê¹Œì§€ í­ë„“ê²Œ ìŠ¤ìº”
                # ---------------------------------------------------
                if not last_col_map:
                    # ì•„ì§ ê¸°ì¤€ í—¤ë”ë¥¼ ë³¸ ì ì´ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
                    continue

                df2 = df.reset_index(drop=True)
                ncols = df2.shape[1]

                col_map = last_col_map.copy()

                # ì´ì–´ì§€ëŠ” í‘œ ìƒë‹¨(0~4í–‰)ì—ì„œ ë‹¤ì‹œ í•œ ë²ˆ ë™/ì¸µ/ì„¸ëŒ€/ì†Œê³„ ìœ„ì¹˜ë¥¼ ë³´ì •
                tmp_map: Dict[str, int] = {}
                max_head_rows = min(5, df2.shape[0])

                for c in range(ncols):
                    pieces = []
                    for r_head in range(max_head_rows):
                        pieces.append(str(df2.iloc[r_head, c]))
                    hdr = "".join(pieces)
                    hdr = hdr.replace(" ", "").replace("\n", "")

                    if ("ë™" in hdr and "í˜¸" in hdr) or "ë™/í˜¸" in hdr:
                        tmp_map["ë™/í˜¸ë³„"] = c
                    elif "ì¸µêµ¬ë¶„" in hdr or ("ì¸µ" in hdr and "êµ¬ë¶„" in hdr):
                        tmp_map["ì¸µêµ¬ë¶„"] = c
                    elif "í•´ë‹¹ì„¸ëŒ€ìˆ˜" in hdr or "í•´ë‹¹ì„¸ëŒ€" in hdr:
                        tmp_map["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] = c
                    elif "ê³µê¸‰ê¸ˆì•¡" in hdr and "ì†Œê³„" in hdr:
                        tmp_map["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] = c

                # ë°œê²¬ëœ ê²Œ ìˆìœ¼ë©´ ê¸°ì¤€ ë§µ ë®ì–´ì“°ê¸°
                col_map.update(tmp_map)

                # ê·¸ë˜ë„ í•µì‹¬ ì»¬ëŸ¼ì´ í•˜ë‚˜ë„ ì•ˆ ì¡íˆë©´ ì´ í‘œëŠ” í¬ê¸°
                if not (col_map.get("ë™/í˜¸ë³„") or col_map.get("ì¸µêµ¬ë¶„") or col_map.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜")):
                    continue
                if not col_map.get("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"):
                    continue

            # ---------------------------------------------------
            # ë°ì´í„° í–‰ íŒŒì‹±
            # ---------------------------------------------------
            start_row = 1 if header_idx is not None else 0

            for r in range(start_row, df2.shape[0]):
                row = df2.iloc[r]
                row_txt = "".join(str(x) for x in row.tolist())

                # ì¤‘ê°„ì— ë˜ ë‚˜ì˜¤ëŠ” í—¤ë” / í•©ê³„ í–‰ì€ ìŠ¤í‚µ
                if "ì£¼íƒí˜•" in row_txt and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt):
                    continue
                if "í•©ê³„" in row_txt:
                    continue

                def get_val(idx: int | None) -> str:
                    if idx is None or idx >= len(row):
                        return ""
                    return str(row.iloc[idx]).strip()

                # ì£¼íƒí˜• / ì•½ì‹í‘œê¸° â†’ forward-fill
                idx_type = col_map.get("ì£¼íƒí˜•")
                if idx_type is not None:
                    v = get_val(idx_type)
                    if v:
                        current_type = v

                idx_abbr = col_map.get("ì•½ì‹í‘œê¸°")
                if idx_abbr is not None:
                    v = get_val(idx_abbr)
                    if v:
                        current_abbr = v

                rec: Dict[str, str] = {
                    "ì£¼íƒí˜•": current_type,
                    "ì•½ì‹í‘œê¸°": current_abbr,
                    "ë™/í˜¸ë³„": get_val(col_map.get("ë™/í˜¸ë³„")),
                    "ì¸µêµ¬ë¶„": get_val(col_map.get("ì¸µêµ¬ë¶„")),
                    "í•´ë‹¹ì„¸ëŒ€ìˆ˜": get_val(col_map.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜")),
                    "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„": get_val(col_map.get("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„")),
                }

                # ğŸ”¹ ì§„ì§œ ê³µê¸‰ê¸ˆì•¡ í–‰ë§Œ ë‚¨ê¸°ê¸° ìœ„í•œ í•„í„°ë“¤ ğŸ”¹

                # 1) ë™/í˜¸, ì¸µ, í•´ë‹¹ì„¸ëŒ€ìˆ˜ ì…‹ ë‹¤ ë¹„ì–´ ìˆìœ¼ë©´ ìš”ì•½í–‰ìœ¼ë¡œ ë³´ê³  ì œê±°
                if not (rec["ë™/í˜¸ë³„"] or rec["ì¸µêµ¬ë¶„"] or rec["í•´ë‹¹ì„¸ëŒ€ìˆ˜"]):
                    continue

                # 2) ê³µê¸‰ê¸ˆì•¡ ì†Œê³„ê°€ ë„ˆë¬´ ì‘ì€ ìˆ«ì(ë©´ì  ë“±)ë©´ ì œê±°
                amt_digits = re.sub(r"[^0-9]", "", rec["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] or "")
                if not amt_digits:
                    continue
                if len(amt_digits) <= 6:
                    continue

                # 3) íƒ€ì… ì •ë³´ê°€ ì „í˜€ ì—†ìœ¼ë©´ (ì§„ì§œë¡œ ì´ìƒí•œ í–‰) ì œê±°
                if not rec["ì£¼íƒí˜•"] and not rec["ì•½ì‹í‘œê¸°"]:
                    continue

                results.append(rec)

    return results

# ============================
#  ê³µê¸‰ê¸ˆì•¡í‘œ ì¶”ì¶œ (ë™Â·í˜¸Â·ì¸µë³„, ì „ì²´ íƒ€ì…)
# ============================
def extract_price_table_from_tables(pdf) -> List[Dict[str, str]]:
    """
    'ê³µê¸‰ê¸ˆì•¡í‘œ'ì—ì„œ
    - ì£¼íƒí˜•
    - ì•½ì‹í‘œê¸°
    - ë™/í˜¸ë³„
    - ì¸µêµ¬ë¶„
    - í•´ë‹¹ì„¸ëŒ€ìˆ˜
    - ê³µê¸‰ê¸ˆì•¡ ì†Œê³„
    ë¥¼ ë½‘ì•„ì˜¨ë‹¤.

    ğŸ”¹ íŠ¹ì§•
    1) ì˜µì…˜í‘œ(ì„ íƒì˜µì…˜, í™•ì¥ë¹„ ë“±)ëŠ” ì „ë¶€ ì œì™¸
    2) 1ê°œ íƒ€ì…ì´ ì—¬ëŸ¬ í˜ì´ì§€/ì—¬ëŸ¬ í…Œì´ë¸”ë¡œ ëŠì–´ì ¸ ìˆì–´ë„ ì´ì–´ì„œ ìˆ˜ì§‘
       (6í˜ì´ì§€ í—¤ë” + 7~9í˜ì´ì§€ ë³¸ë¬¸ì²˜ëŸ¼)
    3) 'ë¶€ë¶„', 'ì „ íƒ€ì…' ê°™ì€ ìš”ì•½í–‰ / ë©´ì í‘œëŠ” ì œê±°
    """

    results: List[Dict[str, str]] = []

    last_col_map: Dict[str, int] | None = None
    current_type = ""
    current_abbr = ""
    current_dongho = ""  # ë™/í˜¸ë³„ forward-fill

    def is_floor_like(s: str) -> bool:
        if not s:
            return False
        s2 = s.replace(" ", "")
        return ("ì¸µ" in s2) and not ("ë™" in s2 or "í˜¸" in s2)

    for page_idx, page in enumerate(pdf.pages):
        tables = page.extract_tables() or []
        for table_idx, table in enumerate(tables):
            if not table or len(table) < 2:
                continue

            df = pd.DataFrame(table).fillna("")
            all_txt = "".join(df.astype(str).values.ravel()).replace(" ", "")

            # 1) ì˜µì…˜/ì„ íƒì‚¬ì–‘ í‘œëŠ” í†µì§¸ë¡œ ìŠ¤í‚µ
            if any(k in all_txt for k in ["ì˜µì…˜", "ì„ íƒí’ˆëª©", "ì„ íƒì‚¬ì–‘"]):
                continue

            # 2) ê³µê¸‰ê¸ˆì•¡í‘œ í›„ë³´ í•„í„°
            has_price = ("ê³µê¸‰ê¸ˆì•¡" in all_txt and "ì†Œê³„" in all_txt)
            has_dongho = ("ë™" in all_txt and "í˜¸" in all_txt) or "ë™/í˜¸" in all_txt
            has_floor = "ì¸µêµ¬ë¶„" in all_txt or ("ì¸µ" in all_txt and "êµ¬ë¶„" in all_txt)
            has_haedang = "í•´ë‹¹ì„¸ëŒ€" in all_txt

            if not has_price and not last_col_map:
                continue
            if not (has_dongho or has_floor or has_haedang):
                continue

            # ---------------- A. ì™„ì „í•œ í—¤ë”(ì£¼íƒí˜•+ì•½ì‹í‘œê¸°) íƒìƒ‰ ----------------
            header_idx = None
            for i, row in df.iterrows():
                row_txt = "".join(str(x) for x in row.tolist())
                if (
                    "ì£¼íƒí˜•" in row_txt
                    and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹ í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt)
                ):
                    header_idx = i
                    break

            col_map: Dict[str, int] = {}

            if header_idx is not None:
                df2 = df.iloc[header_idx:].reset_index(drop=True)
                ncols = df2.shape[1]

                for c in range(ncols):
                    hdr = "".join(df2.iloc[0:4, c].astype(str).tolist())
                    hdr = hdr.replace(" ", "").replace("\n", "")

                    if "ì£¼íƒí˜•" in hdr:
                        col_map["ì£¼íƒí˜•"] = c
                    elif "ì•½ì‹í‘œê¸°" in hdr or "ì•½ì‹í‘œì‹œ" in hdr or "ì•½ì‹" in hdr:
                        col_map["ì•½ì‹í‘œê¸°"] = c
                    elif ("ë™" in hdr and "í˜¸" in hdr) or "ë™/í˜¸" in hdr:
                        col_map["ë™/í˜¸ë³„"] = c
                    elif "ì¸µêµ¬ë¶„" in hdr or ("ì¸µ" in hdr and "êµ¬ë¶„" in hdr):
                        col_map["ì¸µêµ¬ë¶„"] = c
                    elif "í•´ë‹¹ì„¸ëŒ€ìˆ˜" in hdr or "í•´ë‹¹ì„¸ëŒ€" in hdr:
                        col_map["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] = c
                    elif "ê³µê¸‰ê¸ˆì•¡" in hdr and "ì†Œê³„" in hdr:
                        # 'ê³µê¸‰ê¸ˆì•¡ ì†Œê³„'ê°€ ëª…ì‹œëœ ì»¬ëŸ¼ â†’ ì¼ë‹¨ í›„ë³´ë¡œ ì„¤ì •
                        col_map["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] = c
                    elif "ì†Œê³„" in hdr:
                        # ì—¬ëŸ¬ 'ì†Œê³„' ì¤‘ì—ì„œëŠ” í•­ìƒ ê°€ì¥ ì˜¤ë¥¸ìª½(ë§ˆì§€ë§‰)ì„ ì‚¬ìš©
                        col_map["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] = c

                if "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„" not in col_map:
                    continue

                last_col_map = col_map.copy()

            else:
                # ------------- B. í—¤ë” ì—†ëŠ” ì´ì–´ì§€ëŠ” í‘œ(7~9í˜ì´ì§€) -------------
                if not last_col_map:
                    continue

                df2 = df.reset_index(drop=True)
                ncols = df2.shape[1]

                col_map = last_col_map.copy()

                tmp_map: Dict[str, int] = {}
                max_head_rows = min(5, df2.shape[0])

                for c in range(ncols):
                    pieces = []
                    for r_head in range(max_head_rows):
                        pieces.append(str(df2.iloc[r_head, c]))
                    hdr = "".join(pieces).replace(" ", "").replace("\n", "")

                    if ("ë™" in hdr and "í˜¸" in hdr) or "ë™/í˜¸" in hdr:
                        tmp_map["ë™/í˜¸ë³„"] = c
                    elif "ì¸µêµ¬ë¶„" in hdr or ("ì¸µ" in hdr and "êµ¬ë¶„" in hdr):
                        tmp_map["ì¸µêµ¬ë¶„"] = c
                    elif "í•´ë‹¹ì„¸ëŒ€ìˆ˜" in hdr or "í•´ë‹¹ì„¸ëŒ€" in hdr:
                        tmp_map["í•´ë‹¹ì„¸ëŒ€ìˆ˜"] = c
                    elif "ê³µê¸‰ê¸ˆì•¡" in hdr and "ì†Œê³„" in hdr:
                        tmp_map["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] = c
                    elif "ì†Œê³„" in hdr:
                        tmp_map["ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"] = c  # ê°€ì¥ ì˜¤ë¥¸ìª½ ì†Œê³„ê°€ ë®ì–´ì“°ê²Œ í•¨

                col_map.update(tmp_map)

                if not (col_map.get("ë™/í˜¸ë³„") or col_map.get("ì¸µêµ¬ë¶„") or col_map.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜")):
                    continue
                if "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„" not in col_map:
                    continue

            # ---------------------- ë°ì´í„° í–‰ íŒŒì‹± ----------------------
            start_row = 1 if header_idx is not None else 0

            for r in range(start_row, df2.shape[0]):
                row = df2.iloc[r]
                row_txt = "".join(str(x) for x in row.tolist())

                if "ì£¼íƒí˜•" in row_txt and ("ì•½ì‹í‘œê¸°" in row_txt or "ì•½ì‹" in row_txt):
                    continue
                if "í•©ê³„" in row_txt:
                    continue

                def get_val(idx: int | None) -> str:
                    if idx is None or idx >= len(row):
                        return ""
                    return str(row.iloc[idx]).strip()

                # ì£¼íƒí˜• / ì•½ì‹í‘œê¸°
                idx_type = col_map.get("ì£¼íƒí˜•")
                if idx_type is not None:
                    v = get_val(idx_type)
                    if v:
                        current_type = v

                idx_abbr = col_map.get("ì•½ì‹í‘œê¸°")
                if idx_abbr is not None:
                    v = get_val(idx_abbr)
                    if v:
                        current_abbr = v

                # ë™/í˜¸ / ì¸µ ì²˜ë¦¬
                idx_dongho = col_map.get("ë™/í˜¸ë³„")
                raw_dongho = get_val(idx_dongho) if idx_dongho is not None else ""

                floor_val = get_val(col_map.get("ì¸µêµ¬ë¶„")) if col_map.get("ì¸µêµ¬ë¶„") is not None else ""

                if raw_dongho:
                    if is_floor_like(raw_dongho):
                        # ë™/í˜¸ ì¹¸ì— ì¸µ ì •ë³´ê°€ ë“¤ì–´ì˜¨ ê²½ìš° â†’ ë™/í˜¸ëŠ” ì´ì „ê°’ ìœ ì§€, ì¸µìœ¼ë¡œ ì‚¬ìš©
                        if not is_floor_like(floor_val):
                            floor_val = raw_dongho
                    else:
                        current_dongho = raw_dongho

                # ì¸µêµ¬ë¶„ì— 'ì¸µ' ê¸€ìê°€ ë¹ ì ¸ ìˆìœ¼ë©´ ë³´ì • (ìˆ«ì ë˜ëŠ” ë²”ìœ„ë§Œ ìˆì„ ë•Œ)
                if floor_val:
                    fv = floor_val.replace(" ", "")
                    if ("ì¸µ" not in fv) and re.search(r"\d", fv):
                        floor_val = fv + "ì¸µ"

                haedang_val = get_val(col_map.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜")) if col_map.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜") is not None else ""
                price_val = get_val(col_map.get("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„"))

                # ê³µê¸‰ê¸ˆì•¡ì´ ë©´ì ì²˜ëŸ¼ ë„ˆë¬´ ì‘ìœ¼ë©´ ì œê±°
                amt_digits = re.sub(r"[^0-9]", "", price_val or "")
                if not amt_digits or len(amt_digits) <= 6:
                    continue

                rec: Dict[str, str] = {
                    "ì£¼íƒí˜•": current_type,
                    "ì•½ì‹í‘œê¸°": current_abbr,
                    "ë™/í˜¸ë³„": current_dongho,
                    "ì¸µêµ¬ë¶„": floor_val,
                    "í•´ë‹¹ì„¸ëŒ€ìˆ˜": haedang_val,
                    "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„": price_val,
                }

                # ë™/í˜¸, ì¸µ, í•´ë‹¹ì„¸ëŒ€ìˆ˜ ì…‹ ë‹¤ ë¹„ë©´ ë²„ë¦¼
                if not (rec["ë™/í˜¸ë³„"] or rec["ì¸µêµ¬ë¶„"] or rec["í•´ë‹¹ì„¸ëŒ€ìˆ˜"]):
                    continue
                if not rec["ì£¼íƒí˜•"] and not rec["ì•½ì‹í‘œê¸°"]:
                    continue

                results.append(rec)

    return results




# ============================
# Streamlit UI
# ============================
st.set_page_config(page_title="ì…ì£¼ìëª¨ì§‘ê³µê³  ë¶„ì„ê¸°", layout="wide")

st.sidebar.title("ğŸ“‚ PDF ì—…ë¡œë“œ")
uploaded = st.sidebar.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])

st.title("ğŸ¢ ì…ì£¼ìëª¨ì§‘ê³µê³  ë¶„ì„ê¸° (ìë™ ë¶„ì„)")

if uploaded:
    uploaded.seek(0)
    text = ""
    with pdfplumber.open(uploaded) as pdf:
        for p in pdf.pages:
            text += (p.extract_text() or "") + "\n"

    text = filter_irrelevant_sections(text)

    uploaded.seek(0)
    with pdfplumber.open(uploaded) as pdf:
        schedule = extract_schedule_from_table(pdf)
        table_company = extract_company_from_table(pdf, text)
        supply_rows = extract_supply_target_from_tables(pdf)
        price_rows = extract_price_table_from_tables(pdf)

    core = extract_core_info(text)
    loan_cond = extract_loan_condition(text)
    move_in = extract_move_in_date(text)

    st.subheader("ğŸ§  ìë™ ë¶„ì„ ê²°ê³¼")

    st.markdown(f"**ğŸ¢ ë‹¨ì§€ëª…:** {parse_complex_name(text) or 'ì •ë³´ ì—†ìŒ'}")
    st.markdown(f"**ğŸ“ ê³µê¸‰ ìœ„ì¹˜:** {parse_location(text) or 'ì •ë³´ ì—†ìŒ'}")

    st.subheader("ğŸ“Œ í•µì‹¬ ì •ë³´ ìš”ì•½")
    st.write(f"- **ê³µê¸‰ê·œëª¨:** {core.get('ê³µê¸‰ê·œëª¨') or 'ì •ë³´ ì—†ìŒ'}")
    st.write(f"- **ì…ì£¼ì˜ˆì •ì¼:** {move_in or 'ì •ë³´ ì—†ìŒ'}")

    final_siheng = table_company.get("ì‹œí–‰ì‚¬") or core.get("ì‹œí–‰ì‚¬")
    st.write(f"- **ì‹œí–‰ì‚¬:** {final_siheng or 'ì •ë³´ ì—†ìŒ'}")

    final_sigong = table_company.get("ì‹œê³µì‚¬") or core.get("ì‹œê³µì‚¬")
    st.write(f"- **ì‹œê³µì‚¬:** {final_sigong or 'ì •ë³´ ì—†ìŒ'}")

    final_agency = table_company.get("ë¶„ì–‘ëŒ€í–‰ì‚¬")
    if final_agency:
        st.write(f"- **ë¶„ì–‘ëŒ€í–‰ì‚¬:** {final_agency}")

    st.write(f"- **ì¤‘ë„ê¸ˆ ëŒ€ì¶œ ì¡°ê±´:** {loan_cond or 'ì •ë³´ ì—†ìŒ'}")

    st.subheader("ğŸ“… ì²­ì•½ ì¼ì • ìë™ ë¶„ë¥˜")

    order = [
        "ì…ì£¼ìëª¨ì§‘ê³µê³ ì¼",
        "íŠ¹ë³„ê³µê¸‰ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 1ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ì¼ë°˜ê³µê¸‰ 2ìˆœìœ„ ì ‘ìˆ˜ì¼",
        "ë‹¹ì²¨ìë°œí‘œì¼",
        "ì„œë¥˜ì ‘ìˆ˜",
        "ê³„ì•½ì²´ê²°",
    ]

    rows = []
    for key in order:
        val = schedule.get(key)
        rows.append({"í•­ëª©": key, "ì¼ì •": val or "ì •ë³´ ì—†ìŒ"})
        st.write(f"- **{key}**: {val or 'ì •ë³´ ì—†ìŒ'}")

    df_schedule = pd.DataFrame(rows)
    st.table(df_schedule)

    st.subheader("ğŸ  ê³µê¸‰ëŒ€ìƒ (íƒ€ì…ë³„ ìš”ì•½)")
    if supply_rows:
        df_supply = pd.DataFrame(supply_rows)
        st.table(df_supply)
    else:
        st.info("ê³µê¸‰ëŒ€ìƒ í‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.subheader("ğŸ’° ê³µê¸‰ê¸ˆì•¡í‘œ (ë™Â·í˜¸Â·ì¸µë³„)")
    if price_rows:
        df_price = pd.DataFrame(price_rows)
        st.table(df_price)
    else:
        st.info("ê³µê¸‰ê¸ˆì•¡í‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    complex_name = parse_complex_name(text) or ""
    location = parse_location(text) or ""

    # ì—‘ì…€ìš©ìœ¼ë¡œë„ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì •ë¦¬ (í˜¹ì‹œë¼ë„ ìƒê¸¸ ê²½ìš° ëŒ€ë¹„)
    clean_price_rows = []
    for row in price_rows:
        clean = {
            "ì£¼íƒí˜•": row.get("ì£¼íƒí˜•", ""),
            "ì•½ì‹í‘œê¸°": row.get("ì•½ì‹í‘œê¸°", ""),
            "ë™/í˜¸ë³„": row.get("ë™/í˜¸ë³„", ""),
            "ì¸µêµ¬ë¶„": row.get("ì¸µêµ¬ë¶„", ""),
            "í•´ë‹¹ì„¸ëŒ€ìˆ˜": row.get("í•´ë‹¹ì„¸ëŒ€ìˆ˜", ""),
            "ê³µê¸‰ê¸ˆì•¡ ì†Œê³„": row.get("ê³µê¸‰ê¸ˆì•¡ ì†Œê³„", ""),
        }
        clean_price_rows.append(clean)

    excel_bytes = make_excel_file(
        complex_name=complex_name,
        location=location,
        core=core,
        move_in=move_in,
        final_siheng=final_siheng,
        final_sigong=final_sigong,
        final_agency=final_agency,
        loan_cond=loan_cond,
        schedule_rows=rows,
        supply_rows=supply_rows,
        price_rows=clean_price_rows,
    )

    st.download_button(
        label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=excel_bytes,
        file_name=f"{complex_name or 'ë¶„ì–‘ë‹¨ì§€'}_ëª¨ì§‘ê³µê³ _ìë™ë¶„ì„.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

else:
    st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
